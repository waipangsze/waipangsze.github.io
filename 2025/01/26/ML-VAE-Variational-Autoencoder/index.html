

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=light>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="wpsze">
  <meta name="keywords" content="">
  
    <meta name="description" content="基礎知識回顧  Latent Variable Variations Gaussian Mixture Model  Gaussian Mixture Model，即高斯混合模型。生成模型比較主流的三個模型為：隱馬可夫模型HMM、樸素貝葉斯模型NB、高斯混合模型GMM。這裡我們主要為大家介紹GMM。  混合模型是一個可以用來表示在總體分佈中含有N個子分佈的機率模型，它表示了觀測資料在總體中的機率分">
<meta property="og:type" content="article">
<meta property="og:title" content="ML | VAE Variational Auto-Encoder">
<meta property="og:url" content="https://waipangsze.github.io/2025/01/26/ML-VAE-Variational-Autoencoder/index.html">
<meta property="og:site_name" content="wpsze">
<meta property="og:description" content="基礎知識回顧  Latent Variable Variations Gaussian Mixture Model  Gaussian Mixture Model，即高斯混合模型。生成模型比較主流的三個模型為：隱馬可夫模型HMM、樸素貝葉斯模型NB、高斯混合模型GMM。這裡我們主要為大家介紹GMM。  混合模型是一個可以用來表示在總體分佈中含有N個子分佈的機率模型，它表示了觀測資料在總體中的機率分">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.imgur.com/JzSVy2C.png">
<meta property="article:published_time" content="2025-01-25T16:07:00.000Z">
<meta property="article:modified_time" content="2025-01-28T06:24:14.829Z">
<meta property="article:author" content="wpsze">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="ML">
<meta property="article:tag" content="NWP">
<meta property="article:tag" content="VAE">
<meta property="article:tag" content="Auto-Encoder">
<meta property="article:tag" content="Generative AI">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://i.imgur.com/JzSVy2C.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>ML | VAE Variational Auto-Encoder - wpsze</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"waipangsze.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>wpsze</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>Links</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/bookmark/" target="_self">
                <i class="iconfont icon-bookmark"></i>
                <span>Bookmarks</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                <span>Docs</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/Physics/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>Physics</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/Maths/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>Maths</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/CFD/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>CFD</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/ML/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>ML</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/Meteorology/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>Meteorology</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/MPAS/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>MPAS</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/monitor/" target="_self">
                    
                    <span>Real Time Monitoring</span>
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About Me</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://i.imgur.com/JzSVy2C.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="ML | VAE Variational Auto-Encoder"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-01-26 00:07" pubdate>
          January 26, 2025 am
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          4.7k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          40 mins
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> views
        </span>
        

      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">ML | VAE Variational Auto-Encoder</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="基礎知識回顧">基礎知識回顧</h1>
<ul>
<li>Latent Variable</li>
<li>Variations</li>
<li>Gaussian Mixture Model
<ul>
<li><strong>Gaussian Mixture Model</strong>，即高斯混合模型。生成模型比較主流的三個模型為：隱馬可夫模型HMM、樸素貝葉斯模型NB、高斯混合模型GMM。這裡我們主要為大家介紹GMM。
<ul>
<li>混合模型是一個可以用來表示在總體分佈中含有N個子分佈的機率模型，它表示了觀測資料在總體中的機率分佈。利用混合模型計算總體分佈機率時我們並不需要知道原始觀測資料中子分佈的資訊。由 Fourier Theory 可得，任一隨時間做週期性變化的波，都可以分解為一系列不同頻率、不同振幅、不同相位的正弦波。同樣地，我們也可以用多個常態分佈的疊加去逼近任一個分佈。</li>
</ul></li>
</ul></li>
<li>Conditional Probability
<ul>
<li><strong>Conditional Probability</strong>：條件機率。定義兩個事件A和時間B，求A和B同時發生的機率：</li>
<li><span class="math inline">\(P(A, B) = P(B) P(A|B) = P(A) P(B|A)\)</span></li>
</ul></li>
<li>KL divergence
<ul>
<li>KL divergence：KL散度又稱為KL距離或相對熵，用於衡量兩個機率分佈之間的距離。給定真實分佈 <span class="math inline">\(P(x)\)</span> 和理論分佈 <span class="math inline">\(Q(x)\)</span>，我們將它們之間的KL散度公式定義為：</li>
<li><span class="math inline">\(KL (P||Q) = \sum P(x) \log (\dfrac{P(x)}{Q(x)}) = \int P(x) \log (\dfrac{P(x)}{Q(x)}) dx\)</span></li>
<li>此外，關於 KL 散度的一些性質如下：
<ul>
<li><strong>KL散度是不對稱的</strong>：因為P到Q的距離不等於Q到P的距離，即 <span class="math inline">\(KL(P||Q)≠KL(Q||P)\)</span> 。這很容易造成 model collapse 即模式坍縮－模型傾向於產生一些比較容易騙過判別器的樣本，加快模型的收斂，從而導致生成的多樣性變差，生成出來的效果也比較差，相當於走捷徑。</li>
<li>當且僅當兩個分佈完全一致時，KL散度等於0。</li>
</ul></li>
</ul></li>
<li>Maximum Likelihood Estimate
<ul>
<li>Maximum Likelihood Estimate，MLE：極大似然估計。要理解什麼是極大似然估計，我們要先理解什麼是“似然”，它同一般的機率事件又有啥區別？給定一個函數 <span class="math inline">\(P(x|\theta)\)</span>， <span class="math inline">\(x\)</span> 代表樣本點， <span class="math inline">\(\theta\)</span> 表示參數：
<ul>
<li>當 <span class="math inline">\(\theta\)</span> 為常數， <span class="math inline">\(x\)</span> 為變數時，我們稱 為關於 的<strong>機率函數</strong>；</li>
<li>當 <span class="math inline">\(x\)</span> 為常數， <span class="math inline">\(\theta\)</span> 為變數時，我們稱 為關於 的<strong>似然函數</strong></li>
</ul></li>
<li>極大似然估計中樣本點的取樣都必須滿足 i.i.d.，它尋找的是使得樣本點 <span class="math inline">\(x\)</span> 能夠以最大機率發生的 <span class="math inline">\(\theta\)</span> 的取值</li>
</ul></li>
</ul>
<h1 id="applications">Applications</h1>
<p>Auto-Encoders are a specialized type of neural network primarily used for <strong>unsupervised learning tasks</strong>. They function by compressing input data into a lower-dimensional representation and then reconstructing the original data from this compressed form. Below are some key applications and functionalities of autoencoders.</p>
<p>自動編碼器（Autoencoder）在多種情境下表現出色，特別是在無監督學習和數據處理方面。以下是一些自動編碼器最有效的應用場景：</p>
<h2 id="自動編碼器的有效情境">自動編碼器的有效情境</h2>
<ol type="1">
<li><strong>特徵降維</strong>：
<ul>
<li>自動編碼器能夠將高維數據壓縮到低維空間，提取出數據中的關鍵特徵，這一過程類似於主成分分析（PCA），但通常能捕捉更複雜的非線性結構.</li>
</ul></li>
<li><strong>數據去噪</strong>：
<ul>
<li>去噪自動編碼器（Denoising Autoencoder）專門設計用來從受損或帶噪聲的數據中恢復原始信號，這在圖像處理和音頻信號處理中非常有效.</li>
</ul></li>
<li><strong>異常檢測</strong>：
<ul>
<li>自動編碼器可以用於識別異常數據點。通過訓練模型重建正常數據，當輸入異常數據時，重建誤差會顯著增加，從而標識出異常.</li>
</ul></li>
<li><strong>生成模型</strong>：
<ul>
<li>變分自動編碼器（Variational Autoencoder, VAE）和對抗自動編碼器（Adversarial Autoencoder, AAE）等擴展版本可用於生成新樣本，如圖像或時間序列數據，這在創意應用中非常有用.</li>
</ul></li>
<li><strong>特徵提取</strong>：
<ul>
<li>自動編碼器可以作為特徵提取器，將學習到的隱含表示用於後續的有監督學習任務，提升模型性能.</li>
</ul></li>
<li><strong>圖像重建與修復</strong>：
<ul>
<li>在計算機視覺領域，自動編碼器可以用於圖像重建和修復，例如從模糊或部分損壞的圖像中重建清晰的圖像.</li>
</ul></li>
</ol>
<p>Input = image, text</p>
<div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/0EJzfPK.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/i8javUE.png" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"></div></div>
<h1 id="auto-encoder">Auto-Encoder</h1>
<p>Auto-Encoder自編碼器是1986年由 Rumelhart 提出，可用於高維複雜資料的處理, 它促進了神經網路的發展。自編碼神經網路是一種<strong>無監督學習演算法</strong>（訓練範例未標註），它使用了BP反向傳播演算法，致力於使輸出與輸入越接近越好。</p>
<h2 id="structure-of-auto-encoder">Structure of Auto-Encoder</h2>
<p>An Auto-Encoder typically consists of three main components:</p>
<ul>
<li><strong>Encoder</strong>: Compresses the input data into a lower-dimensional representation.</li>
<li><strong>Bottleneck (Code)</strong>: Contains the compressed representation of the input.</li>
<li><strong>Decoder</strong>: Reconstructs the original input from the compressed representation.<br />
</li>
<li><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/shu8T3B.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/Qx6HPqW.png" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/OmfCUi2.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/yewPTO0.png" srcset="/img/loading.gif" lazyload /></div></div></div></li>
</ul>
<h2 id="自編碼器的限制在哪裡">自編碼器的限制在哪裡？</h2>
<p>透過AE建構出一個比PCA更清晰的自編碼器模型，<strong>但這並不是真正意義上的生成模型</strong>。對於一個特定的生成模型，它一般應該滿足以下兩點：</p>
<ul>
<li>編碼器和解碼器是可以獨立分割的（類比GAN的Generator和Discriminator）</li>
<li>固定維度下任意取樣出來的編碼，都應該能透過解碼器產生一張清晰且真實的圖片</li>
</ul>
<p>這裡解釋下第二點。如下圖所示，我們用一張全月圖和一張半月圖去訓練一個AE，經過訓練，模型能夠很好地還原出這兩張圖片。接下來，我們在latent code上中間一點，即兩張圖片編碼點中間處任取一點，將這點交給解碼器進行解碼，直覺上我們會得到一張介於全月圖和半月圖之間的圖片（如陰影面積覆蓋3/4的樣子）。然而，實際上當你那這個點去decode的時候你會發現AE還原出來的圖片不僅模糊而且還是亂碼的。為什麼會出現這種現象？一個直觀上的解釋是AE的Encoder和Decoder都使用了 DNN，<strong>DNN是一個非線性的變換過程，因此在latent space上點與點之間transform往往沒有規律可循</strong>。</p>
<h3 id="引入噪聲-隨機性">引入噪聲 (隨機性)</h3>
<div class="note note-primary">
            <p>如何解決這個問題呢？<strong>一個想法就是引入噪聲</strong>，擴大圖片的編碼區域，從而能夠覆蓋到失真的空白編碼區。其實說白了就是透過增加輸入的多樣性來增強輸出的魯棒性。當我們將輸入圖片編碼之前引入一點噪聲，使得每張圖片的編碼點出現在綠色箭頭範圍內，這樣一來所得到的latent space就能覆蓋到更多的編碼點。此時我們再從中間點抽取去還原便可以得到一個我們比較希望得到的輸出。</p>
          </div>
<p>雖然我們為輸入圖片增添了一些噪音 (引入噪聲) 使得latent space能夠覆蓋到比較多的區域，但是還是有不少地方沒有被覆蓋到，比如上圖右邊黃色的部分因為離得比較遠所以就沒編碼到。因此，我們是否可以嘗試利用更多的噪音，使得對於每一個輸入樣本，它的編碼都能夠覆蓋到整個編碼空間？只不過這裡我們需要保證的是，對於源編碼附近的編碼我們應該給定一個高的機率值，而對於距離原編碼點距離較遠的，我們應該給定一個低的機率值。沒錯，整體來說，<strong>我們就是要將原先一個單點拉伸到整個編碼空間，即將離散的編碼點引申為一條連續的接近常態分佈的編碼曲線</strong>。</p>
<div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/WcjuQGm.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/Ahr59Ji.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/9bIChjc.png" srcset="/img/loading.gif" lazyload /></div></div></div>
<p>到這裡，我們已經不知不覺到來到了 <strong>變分自編碼器 VAE 的核心思想腹地</strong>。以下我們將詳細敘述VAE的模型架構。</p>
<h1 id="variational-auto-encoder">Variational Auto-Encoder</h1>
<p>早在2013年，Kingma和Welling就推出了變分自動編碼器（VAE），簡而言之，VAE的想法是訓練具有正則化潛在空間的自動編碼器。然後，正則化編碼器被迫將資料編碼為接近高斯的分佈，而解碼器則從潛在空間重建資料。</p>
<p>變分法便是用來求泛函數的極值。下面就不展開了，有興趣的可以自行查閱相關資料。這裡主要說一點的就是 VAE 中 V 是怎麼來的，認為應該只是計算的過程中用到了變分法的思想去求解，所以就取名叫 VAE。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1312.6114">Kingma, Diederik P. "Auto-encoding variational bayes." arXiv preprint arXiv:1312.6114 (2013).</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1906.02691">An Introduction to Variational Autoencoders (2019)</a></li>
</ul>
<div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/y99QAWW.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/8KvMH5H.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/rO6O6rt.png" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/YGNSOKR.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/7IAIlyS.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/mavnxry.png" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/v9pXyAv.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/0BY1Ikf.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/WY36In6.png" srcset="/img/loading.gif" lazyload /></div></div></div>
<p>最後，再讓我們一起來討論下VAE的限制。雖然VAE比普通的AE模型訓練出來的效果要好得多，但是訓練過VAE模型的人都知道，它生成出來的圖片相對GANs那種直接利用對抗學習的方式會比較模糊，這是由於它是通過直接計算生成圖片和原始圖片之間的均方誤差，所以得到的是一張「平均圖像」。</p>
<h1 id="sampling-引入噪聲">*** Sampling (引入噪聲)</h1>
<p>結構：VAE也是由編碼器和解碼器組成，<strong>但它在編碼階段引入了一個機率模型 (引入噪聲)</strong>。編碼器輸出的是潛在空間的參數（平均值和變異數），而不是直接的潛在表示。解碼器則從這個潛在分佈中取樣產生資料。</p>
<p>目的：VAE的目標不僅是重構輸入數據，<strong>還希望潛在空間的表示具有良好的性質，例如連續性和可解釋性。這使得 VAE 適合產生新數據</strong>。</p>
<p>應用：VAE廣泛應用於生成建模，如影像生成、資料插值和缺失資料填充</p>
<p><img src="https://i.imgur.com/JzSVy2C.png" srcset="/img/loading.gif" lazyload width="800" /></p>
<h2 id="編碼器與機率分佈">編碼器與機率分佈</h2>
<p>編碼器與機率分佈：在 VAE 中，編碼器不是直接輸出潛在變數 <span class="math inline">\(z\)</span> 的值，而是輸出 <span class="math inline">\(z\)</span> 的參數。這通常是潛在空間的均值 <span class="math inline">\(\mu\)</span> 和 方差 <span class="math inline">\(\sigma\)</span>。透過這些參數，我們可以定義一個常態分佈：</p>
<p><span class="math display">\[
z \sim N(\mu(x), \sigma(x))
\]</span></p>
<div class="note note-primary">
            <p>這裡，<span class="math inline">\(\mu(x)\)</span> 和 <span class="math inline">\(\sigma(x)\)</span> 是由編碼器網路產生的。這樣，<span class="math inline">\(z\)</span> 的值就是在<strong>這個分佈中進行取樣</strong>的。</p>
          </div>
<div class="note note-primary">
            <ul><li>編碼器為每個輸入輸出一個多元正態分佈的參數（均值和方差）。從這個分佈中進行採樣可以生成新數據點，通過將這些採樣的潛在向量傳遞給解碼器，<strong>有效地創建出與訓練數據相似但又不同的新實例</strong>。</li><li>採樣過程為模型<strong>引入了隨機性</strong>，這是捕捉數據變異性的關鍵。與傳統的自編碼器產生確定性輸出不同，VAE利用採樣中的隨機性確保從相同輸入生成不同的潛在向量，從而實現對數據的更豐富表示。<strong>這種隨機性有助於從相似輸入中探索多樣化的輸出</strong>。</li><li><strong>這確保了學習到的潛在空間是結構化的，並促進了數據點之間有意義的插值</strong> (!!!)。</li><li>訓練完成後，VAE不僅可以從學習到的後驗分佈中進行採樣，還可以從各種其他分佈中進行採樣。例如，它們可以從先驗分佈（通常是標準正態分佈）中進行採樣，<strong>這可能導致生成多樣的新數據點。這種靈活性使得VAE能夠應用於各種上下文，例如生成圖像或填補缺失數據</strong>。</li></ul>
          </div>
<div class="note note-primary">
            <p>總之，VAE中的採樣對於其生成能力至關重要，引入了必要的隨機性，通過結構化潛在空間幫助正則化，利用重參數化等高效訓練技術，並提供了生成新數據實例的靈活性。</p>
          </div>
<div class="note note-primary">
            <p><strong>但如果</strong>我們從這個分佈中取樣，那麼這個節點 <span class="math inline">\(z\)</span> 將是一個隨機節點，無法進行反向傳播 (不能微分, 採樣本身是不可導的)，這意味著無法進行優化。(為了在訓練過程中允許反向傳播，同時保持隨機採樣，VAE採用了一種稱為<strong>重參數化技巧</strong>的方法。)</p>
          </div>
<h1 id="重參數化技巧-reparameterization-trick">*** 重參數化技巧 (Reparameterization trick)</h1>
<p><img src="https://i.imgur.com/LbEi0j8.png" srcset="/img/loading.gif" lazyload width="600" /></p>
<div class="note note-primary">
            <ul><li><strong>Random node z</strong> can not be done via Backpropagation !!! (直接從這個分佈採樣會導致梯度無法通過隨機節點回傳，因此 <strong>重參數化技巧</strong> 將 <strong>採樣過程</strong> 分解為 <strong>確定性變換</strong>。)</li><li>Then, introduce a <strong>New External Noise Input</strong> <span class="math inline">\(\epsilon\)</span> is <span class="math inline">\(N(0,1)\)</span> !!!</li><li>The <span class="math inline">\(\epsilon\)</span> is <span class="math inline">\(N(0,1)\)</span> and will be not involved into Backpropagation !!! (not on the our Chain Rule !!!)</li></ul>
          </div>
<div class="note note-primary">
            <p>重參數化技巧是指將隨機變量的 <strong>採樣過程轉</strong> 換為一個 <strong>確定性函數</strong> 與 <strong>隨機噪聲</strong> 的組合。這樣做的目的是使得模型在訓練過程中可以進行有效的梯度反向傳播。</p>
          </div>
<p>重參數化技巧：<strong>為了使得 VAE 能夠進行有效的反向傳播</strong>，使用了重參數化技巧。具體來說，我們將 <span class="math inline">\(z\)</span> 表達為：</p>
<p><span class="math display">\[
z = \mu(x) + \sigma(x) \cdot \epsilon
\]</span></p>
<p>其中 <span class="math inline">\(\epsilon \sim N(0,1)\)</span> 。</p>
<div class="note note-primary">
            <ul><li>透過這種方式，<strong>我們可以將隨機性從網路的前向傳播中分離出來，使得我們能夠透過標準的反向傳播演算法來訓練模型</strong>。</li><li>例如，如果 <span class="math inline">\(q_{\phi}(z|x)\)</span> 是均值為 <span class="math inline">\(\mu\)</span>、方差為 <span class="math inline">\(\sigma^2\)</span> 的高斯分佈，可以從標準正態分佈 <span class="math inline">\(N(0, I)\)</span> 中採樣一個噪聲 <span class="math inline">\(\epsilon\)</span>，然後計算 <span class="math inline">\(z = \mu + \sigma \odot \epsilon\)</span>。這樣，<strong><span class="math inline">\(z\)</span> 的採樣就變成了均值和方差的函數，從而使得梯度可以通過 <span class="math inline">\(z\)</span> 回傳</strong>。</li></ul>
          </div>
<h1 id="vae生成的影像品質並不好">VAE生成的影像品質並不好</h1>
<p>目前在影像生成領域，除了VAE，還有GAN，Diffusion模型等，相較之下，VAE生成的影像品質並不好，通常比較模糊。但為什麼在StableDiffusion中，採用了VAE+diffusion的結構，效果就變得非常好了？</p>
<p>過高的壓縮率、重建損失只有平方誤差、完整的KL散度項，都是傳統VAE模糊的原因。而對於傳統VAE來說，能改進的只有重構損失，其實如果你把傳統VAE的重構損失也換成“平方誤差 + perceptual損失 + 對抗損失”，也能明顯減少VAE的模糊。</p>
<p>但是，改進VAE的重構損失只能解決清晰度問題，解決不了壓縮率問題，將一張 256x256 甚至 1024x1024 的圖片壓縮為單一向量，必然會有嚴重的資訊損失，只能重構出一些比較宏觀的語義，細節層面肯定沒辦法更好保留。</p>
<p>相較之下，LDM的VAE只用來壓縮圖片大小，它不負責成為一個生成模型（交給diffusion來做），所以能騰出的空間更多。例如，將壓縮為單一向量改為保留a*b大小的feature map，單這一點就可以讓重構結果清晰不少，然後弱化KL散度項（或者VQ-VAE的VQ作為正則，都差不多，這是為了防止latent的變異數過大）也能讓結果更清晰，更不用說改進重構損失了。</p>
<p>說穿了，LDM的VAE只負責重構出清晰的結果（外加一點正則），它的核心作用的AE而不是VAE，生成能力強是因為Diffusion強。</p>
<p>所以 (latent diffusion model) LDM的VAE可以當做AE來理解，本質上是因為圖片和視訊資訊實在太稀疏了，搞個AE壓縮一下，方便後面diffusion訓練。 KL散度就是懲罰項，讓latent的分佈集中一下，別太分散了，方便後面學習，不考慮 z 一定要用常態分佈採樣。</p>

    <div class="fold">
      <div class="fold-title fold-info collapsed" data-toggle="collapse" href="#collapse-8f7bdefe" role="button" aria-expanded="false" aria-controls="collapse-8f7bdefe">
        <div class="fold-arrow">▶</div>pytorch VAE
      </div>
      <div class="fold-collapse collapse" id="collapse-8f7bdefe">
        <div class="fold-content">
          <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>device = <span class="hljs-string">&quot;cpu&quot;</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;device = &quot;</span>, device)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;torch.__version__ = &quot;</span>, torch.__version__)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;torch.cuda.is_available() = &quot;</span>, torch.cuda.is_available())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;torch.cuda.device_count() = &quot;</span>, torch.cuda.device_count())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;torch.cuda.current_device() =&quot;</span>, torch.cuda.current_device())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;torch.cuda.device(0) = &quot;</span>, torch.cuda.device(<span class="hljs-number">0</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;torch.cuda.get_device_name(0) = &quot;</span>, torch.cuda.get_device_name(<span class="hljs-number">0</span>))<br><br><span class="hljs-comment"># 超参数</span><br>latent_dim = <span class="hljs-number">20</span><br>batch_size = <span class="hljs-number">128</span><br>learning_rate = <span class="hljs-number">1e-3</span><br>num_epochs = <span class="hljs-number">10</span><br><br><span class="hljs-comment"># 数据准备</span><br>transform = transforms.Compose([<br>    transforms.ToTensor(),<br>    <span class="hljs-comment"># transforms.Normalize((0.5,), (0.5,))</span><br>])<br>train_dataset = datasets.MNIST(root=<span class="hljs-string">&#x27;./data&#x27;</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>, transform=transform)<br>train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># VAE模型定义</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">VAE</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, latent_dim</span>):<br>        <span class="hljs-built_in">super</span>(VAE, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-comment"># 编码器</span><br>        <span class="hljs-variable language_">self</span>.encoder = nn.Sequential(<br>            nn.Flatten(),<br>            nn.Linear(<span class="hljs-number">28</span>*<span class="hljs-number">28</span>, <span class="hljs-number">400</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">400</span>, <span class="hljs-number">2</span> * latent_dim)  <span class="hljs-comment"># 输出均值和对数方差</span><br>        )<br>        <span class="hljs-comment"># 解码器</span><br>        <span class="hljs-variable language_">self</span>.decoder = nn.Sequential(<br>            nn.Linear(latent_dim, <span class="hljs-number">400</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">400</span>, <span class="hljs-number">28</span>*<span class="hljs-number">28</span>),<br>            nn.Sigmoid()  <span class="hljs-comment"># 输出范围在[0, 1]之间</span><br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reparameterize</span>(<span class="hljs-params">self, mu, logvar</span>):<br>        std = torch.exp(<span class="hljs-number">0.5</span> * logvar)<br>        eps = torch.randn_like(std)<br>        <span class="hljs-keyword">return</span> mu + eps * std<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 编码</span><br>        mu_logvar = <span class="hljs-variable language_">self</span>.encoder(x)<br>        mu, logvar = mu_logvar[:, :latent_dim], mu_logvar[:, latent_dim:]<br>        z = <span class="hljs-variable language_">self</span>.reparameterize(mu, logvar)<br>        <span class="hljs-comment"># 解码</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.decoder(z), mu, logvar<br><br><span class="hljs-comment"># 损失函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss_function</span>(<span class="hljs-params">recon_x, x, mu, logvar</span>):<br>    BCE = nn.functional.binary_cross_entropy(recon_x, x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">28</span>*<span class="hljs-number">28</span>), reduction=<span class="hljs-string">&#x27;sum&#x27;</span>)<br>    KLD = -<span class="hljs-number">0.5</span> * torch.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span> + logvar - mu.<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>) - logvar.exp())<br>    <span class="hljs-keyword">return</span> BCE + KLD<br><br><span class="hljs-comment"># 初始化模型和优化器</span><br>model = VAE(latent_dim)<br>model.to(device)<br><br>optimizer = optim.Adam(model.parameters(), lr=learning_rate)<br><br><span class="hljs-comment"># 训练模型</span><br>model.train()<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    train_loss = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> batch_idx, (data, _) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>        optimizer.zero_grad()<br>        data = data.to(device)<br>        recon_batch, mu, logvar = model(data)<br>        loss = loss_function(recon_batch, data, mu, logvar)<br>        loss.backward()<br>        train_loss += loss.item()<br>        optimizer.step()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Epoch <span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>&#125;</span>, Loss: <span class="hljs-subst">&#123;train_loss / <span class="hljs-built_in">len</span>(train_loader.dataset):<span class="hljs-number">.4</span>f&#125;</span>&#x27;</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Training finished!&quot;</span>)<br><br><span class="hljs-comment"># 生成图像</span><br>model.<span class="hljs-built_in">eval</span>()<br><span class="hljs-keyword">with</span> torch.no_grad():<br>    sample = torch.randn(<span class="hljs-number">64</span>, latent_dim)  <span class="hljs-comment"># 生成64个潜在样本</span><br>    sample = sample.to(device)<br>    generated_images = model.decoder(sample).view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)  <span class="hljs-comment"># 解码为图像</span><br><br><span class="hljs-comment"># 可视化生成的图像</span><br>grid_img = torchvision.utils.make_grid(generated_images, nrow=<span class="hljs-number">8</span>, normalize=<span class="hljs-literal">True</span>)<br>grid_img = grid_img.cpu()<br>plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>))<br>plt.imshow(grid_img.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>).numpy())<br>plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br><span class="hljs-comment">#plt.show()</span><br>plt.savefig(<span class="hljs-string">&#x27;test.png&#x27;</span>)<br></code></pre></td></tr></table></figure>
        </div>
      </div>
    </div>
<ul>
<li>real time是時脈走過的時間，user time 是程式在使用者狀態的cpu時間，sys time 為程式在內核態的cpu時間</li>
<li><code>%cpu_usage = (user_time + sys_time)/real_time * 100%</code></li>
</ul>
<p>GPU-3090 (only ~7% utility) <figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs console">real	1m16.440s<br>user	1m23.738s<br>sys	0m32.552s<br></code></pre></td></tr></table></figure></p>
<p>CPU (all 20cores are used) <figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs console">real	1m56.233s<br>user	11m45.820s<br>sys	25m28.952s<br></code></pre></td></tr></table></figure></p>
<h1 id="literautre-review">Literautre Review</h1>
<p>The marginal likelihood is composed of a sum over the marginal likelihoods of individual datapoints <span class="math display">\[
\log p_{\boldsymbol{\theta}}(\mathbf{x}^{(1)},\cdots,\mathbf{x}^{(N)})=\sum_{i=1}^{N}\log p_{\boldsymbol{\theta}}(\mathbf{x}^{(i)})
\]</span> , which can each be rewritten as: <span class="math display">\[
\log p_{\boldsymbol{\theta}}(\mathbf{x}^{(i)})=D_{KL}(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})||p_{\boldsymbol{\theta}}(\mathbf{z}|\mathbf{x}^{(i)}))+\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)}) 
\]</span></p>
<p>The fırst RHS term is the KL divergence of the approximate from the true posterior. Since this <strong>KL- divergence is non- negative</strong>, the second RHS term, <span class="math inline">\(\mathcal{L} ( \boldsymbol{\theta }, \boldsymbol{\phi }; \mathbf{x} ^{( i) })\)</span> is called the <strong>(variational) lower bound</strong> on the marginal likelihood of datapoint <span class="math inline">\(i\)</span>, and can be written as:</p>
<p><span class="math display">\[\log p_{\boldsymbol{\theta}}(\mathbf{x}^{(i)})\geq\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})=\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})}\left[-\log q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})+\log p_{\boldsymbol{\theta}}(\mathbf{x},\mathbf{z})\right]\]</span></p>
<p>which can also be written as:</p>
<p><span class="math display">\[\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})=-D_{KL}(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})||p_{\boldsymbol{\theta}}(\mathbf{z}))+\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})}\left[\log p_{\boldsymbol{\theta}}(\mathbf{x}^{(i)}|\mathbf{z})\right]\]</span> We want to differentiate and optimize the lower bound <span class="math inline">\(\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\mathbf{x}^{(i)})\)</span> w.r.t. both the variational parameters <span class="math inline">\(\phi\)</span> and generative parameters <span class="math inline">\(\theta.\)</span> However, the gradient of the lower bound w.r.t. <span class="math inline">\(\phi\)</span> is a bit problematic. The usual (naïve) Monte Carlo gradient estimator for this type of problem is: <span class="math display">\[
\nabla _{\boldsymbol{\phi }}\mathbb{E} _{q_{\boldsymbol{\phi }( \mathbf{z} ) }}\left [ f( \mathbf{z} ) \right ] = \mathbb{E} _{q_{\boldsymbol{\phi }( \mathbf{z} ) }}\left [ f( \mathbf{z} ) \nabla _{q_{\boldsymbol{\phi }( \mathbf{z} ) }}\log q_{\boldsymbol{\phi }}( \mathbf{z} ) \right ] \simeq \frac 1L\sum _{l= 1}^Lf( \mathbf{z} ) \nabla _{q_{\boldsymbol{\phi }( \mathbf{z} ^{( l) }) }}\log q_{\boldsymbol{\phi }}( \mathbf{z} ^{( l) })
\]</span> where <span class="math inline">\(\mathbf{z}^{(l)}\sim q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x}^{(i)}).\)</span> This gradient estimator exhibits exhibits very high variance (see.g. [BJP12]) and is impractical for our purposes.</p>
<div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/qjPqBwc.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/Q6DXjJP.png" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/gC1Dm6T.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/LbEi0j8.png" srcset="/img/loading.gif" lazyload /></div></div></div>
<ul>
<li><strong>Random node <span class="math inline">\(z\)</span></strong> can not be done via Backpropagation!!!</li>
<li>The <span class="math inline">\(\epsilon\)</span> is <span class="math inline">\(N(0,1)\)</span> and will be not involved into Backpropagation!!</li>
</ul>
<h1 id="references">References</h1>
<ol type="1">
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=qJeaCHQ1k2w">Variational Autoencoders | Generative AI Animated</a></li>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=iwEzwTTalbg">Variational Autoencoder - Model, ELBO, loss function and maths explained easily! (<strong>Recommend</strong>)</a></li>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=Dg0YcABQ_aU">台大資訊 深度學習之應用 | ADL 10.3: Variational Auto-Encoder (VAE) 控制特徵的分布以生成用</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/LwtwaPEkrhFMwazY3PfRew">深度理解变分自编码器(VAE) | 从入门到精通</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/ZjAK_Z7jvrPMGslKiYca_Q">VAE原理及示例代码</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/348498294?utm_psn=1866895402294468608">机器学习方法—优雅的模型（一）：变分自编码器（VAE）</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/LFmFXA1hFZE8lesSk1XzzQ">VAE变分自编码器原理解析看这一篇就够了！另附Python代码实现</a></li>
<li><a target="_blank" rel="noopener" href="https://stackabuse.com/autoencoders-for-image-reconstruction-in-python-and-keras/">Autoencoders for Image Reconstruction in Python and Keras</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1906.02691">Diederik P. Kingma and Max Welling (2019), “An Introduction to Variational Autoencoders”, Foundations and Trends in Machine Learning: Vol. xx, No. xx, pp 1–18. DOI: 10.1561/XXXXXXXXX</a></li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/ML/" class="category-chain-item">ML</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/AI/" class="print-no-link">#AI</a>
      
        <a href="/tags/ML/" class="print-no-link">#ML</a>
      
        <a href="/tags/NWP/" class="print-no-link">#NWP</a>
      
        <a href="/tags/VAE/" class="print-no-link">#VAE</a>
      
        <a href="/tags/Auto-Encoder/" class="print-no-link">#Auto-Encoder</a>
      
        <a href="/tags/Generative-AI/" class="print-no-link">#Generative AI</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>ML | VAE Variational Auto-Encoder</div>
      <div>https://waipangsze.github.io/2025/01/26/ML-VAE-Variational-Autoencoder/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>wpsze</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>January 26, 2025</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Updated on</div>
          <div>January 28, 2025</div>
        </div>
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/01/26/ML-ResNet/" title="ML | ResNet">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">ML | ResNet</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/01/25/ML-ECMWF-Anemoi/" title="ML | ECMWF | Anemoi">
                        <span class="hidden-mobile">ML | ECMWF | Anemoi</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.utils.listenDOMLoaded(function() {
      Fluid.events.registerRefreshCallback(function() {
        if ('mermaid' in window) {
          mermaid.init();
        }
      });
    });
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">

  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  

  <span id="sitetime"></span>
  <script language=javascript>
    function siteTime(){
      window.setTimeout("siteTime()", 1000);
      var seconds = 1000;
      var minutes = seconds * 60;
      var hours = minutes * 60;
      var days = hours * 24;
      var years = days * 365;
      var today = new Date();
      var todayYear = today.getFullYear();
      var todayMonth = today.getMonth()+1;
      var todayDate = today.getDate();
      var todayHour = today.getHours();
      var todayMinute = today.getMinutes();
      var todaySecond = today.getSeconds();
      /* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
      year - 作为date对象的年份，为4位年份值
      month - 0-11之间的整数，做为date对象的月份
      day - 1-31之间的整数，做为date对象的天数
      hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
      minutes - 0-59之间的整数，做为date对象的分钟数
      seconds - 0-59之间的整数，做为date对象的秒数
      microseconds - 0-999之间的整数，做为date对象的毫秒数 */
      var t1 = Date.UTC(2023,04,23,00,00,00); //北京时间2018-2-13 00:00:00
      var t2 = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
      var diff = t2-t1;
      var diffYears = Math.floor(diff/years);
      var diffDays = Math.floor((diff/days)-diffYears*365);
      var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
      var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
      var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
      /*document.getElementById("sitetime").innerHTML=" 已运行"+/*diffYears+" 年 "+*/diffDays+" 天 "+diffHours+" 小时 "+diffMinutes+" 分钟 "+diffSeconds+" 秒";
      document.getElementById("sitetime").innerHTML=" 已運行"+diffYears+" 年 "+diffDays+" 天 ";
    }/*因为建站时间还没有一年，就将之注释掉了。需要的可以取消*/
    siteTime();
  </script>
  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
