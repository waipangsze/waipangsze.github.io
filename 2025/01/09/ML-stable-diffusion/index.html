

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=light>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="wpsze">
  <meta name="keywords" content="">
  
    <meta name="description" content="stable-diffusion-xl-base-1.0  https:&#x2F;&#x2F;huggingface.co&#x2F;stabilityai&#x2F;stable-diffusion-xl-base-1.0   The stable-diffusion-xl-base-1.0 is a text-to-image generative model developed by Stability AI.  Inputs">
<meta property="og:type" content="article">
<meta property="og:title" content="ML | stable-diffusion">
<meta property="og:url" content="https://waipangsze.github.io/2025/01/09/ML-stable-diffusion/index.html">
<meta property="og:site_name" content="wpsze">
<meta property="og:description" content="stable-diffusion-xl-base-1.0  https:&#x2F;&#x2F;huggingface.co&#x2F;stabilityai&#x2F;stable-diffusion-xl-base-1.0   The stable-diffusion-xl-base-1.0 is a text-to-image generative model developed by Stability AI.  Inputs">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.imgur.com/imchHVz.png">
<meta property="article:published_time" content="2025-01-09T06:04:00.000Z">
<meta property="article:modified_time" content="2025-10-27T06:03:55.771Z">
<meta property="article:author" content="wpsze">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="ML">
<meta property="article:tag" content="pytorch">
<meta property="article:tag" content="huggingface">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="stable-diffusion">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://i.imgur.com/imchHVz.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>ML | stable-diffusion - wpsze</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"waipangsze.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":"F7MK-FcxSomhtc1N3hIUDA"},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=F7MK-FcxSomhtc1N3hIUDA", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', 'F7MK-FcxSomhtc1N3hIUDA');
        });
      }
    </script>
  

  

  

  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>wpsze</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>Links</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/bookmark/" target="_self">
                <i class="iconfont icon-bookmark"></i>
                <span>Bookmarks</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                <span>Docs</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/Physics/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>Physics</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/Maths/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>Maths</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/CFD/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>CFD</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/ML/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>ML</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/Meteorology/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>Meteorology</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/MPAS/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>MPAS</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/PALM/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>PALM</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/monitor/" target="_self">
                    
                    <span>Real Time Monitoring</span>
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About Me</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://i.imgur.com/imchHVz.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="ML | stable-diffusion"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-01-09 14:04" pubdate>
          January 9, 2025 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          1.5k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          13 mins
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> views
        </span>
        

      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">ML | stable-diffusion</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="stable-diffusion-xl-base-1.0">stable-diffusion-xl-base-1.0</h1>
<ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0" class="uri">https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0</a></li>
</ul>
<p><img src="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/pipeline.png" srcset="/img/loading.gif" lazyload width="500" /></p>
<p>The <code>stable-diffusion-xl-base-1.0</code> is a text-to-image generative model developed by Stability AI.</p>
<ul>
<li>Inputs
<ul>
<li>Text prompt: A description of the desired image, such as "a beautiful sunset over a mountain landscape".</li>
</ul></li>
<li>Outputs
<ul>
<li>Generated image: An image that corresponds to the input text prompt, generated using the model's diffusion-based text-to-image capabilities.</li>
</ul></li>
</ul>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs console">micromamba env create -n SD<br>micromamba activate SD<br>micromamba install python==3.10<br>pip install diffusers --upgrade<br>pip install invisible_watermark transformers accelerate safetensors gradio<br>micromamba install git-lfs<br></code></pre></td></tr></table></figure>
<ul>
<li>When using torch &gt;= 2.0, you can improve the inference speed by 20-30% with torch.compile. Simple wrap the unet with torch compile before running the pipeline:
<ul>
<li><code>pipe.unet = torch.compile(pipe.unet, mode="reduce-overhead", fullgraph=True)</code></li>
</ul></li>
<li>If you are limited by GPU VRAM, you can enable cpu offloading by calling pipe.enable_model_cpu_offload instead of .to("cuda"):
<ul>
<li><code>- pipe.to("cuda")</code></li>
<li><code>+ pipe.enable_model_cpu_offload()</code></li>
</ul></li>
</ul>
<p>The models are saved at,</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs console">6.7G	/home/wpsze/.cache/huggingface/hub/models--stabilityai--stable-diffusion-xl-base-1.0<br>4.4G	/home/wpsze/.cache/huggingface/hub/models--stabilityai--stable-diffusion-xl-refiner-1.0<br></code></pre></td></tr></table></figure>
<h2 id="base-model">base model</h2>
<p>To just use the base model, you can run:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#!/bin/python</span><br><br><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline<br><span class="hljs-keyword">import</span> torch<br><br>pipe = DiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16, use_safetensors=<span class="hljs-literal">True</span>, variant=<span class="hljs-string">&quot;fp16&quot;</span>)<br>pipe.to(<span class="hljs-string">&quot;cuda&quot;</span>)<br><br><span class="hljs-comment"># if using torch &lt; 2.0</span><br><span class="hljs-comment"># pipe.enable_xformers_memory_efficient_attention()</span><br><br>prompt = <span class="hljs-string">&quot;An astronaut riding a green horse&quot;</span><br><br>image = pipe(prompt=prompt).images[<span class="hljs-number">0</span>]<br><br>image.save(<span class="hljs-string">&quot;astronaut_rides_horse.png&quot;</span>) <span class="hljs-comment"># 1024 x 1024</span><br></code></pre></td></tr></table></figure>
<p>GPU: ~ 10GB</p>
<h2 id="base-refiner-pipeline">base + refiner pipeline</h2>
<p>To use the whole base + refiner pipeline as an ensemble of experts you can run:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline<br><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># load both base &amp; refiner</span><br>base = DiffusionPipeline.from_pretrained(<br>    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>, use_safetensors=<span class="hljs-literal">True</span><br>)<br>base.to(<span class="hljs-string">&quot;cuda&quot;</span>)<br>refiner = DiffusionPipeline.from_pretrained(<br>    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-refiner-1.0&quot;</span>,<br>    text_encoder_2=base.text_encoder_2,<br>    vae=base.vae,<br>    torch_dtype=torch.float16,<br>    use_safetensors=<span class="hljs-literal">True</span>,<br>    variant=<span class="hljs-string">&quot;fp16&quot;</span>,<br>)<br>refiner.to(<span class="hljs-string">&quot;cuda&quot;</span>)<br><br><span class="hljs-comment"># Define how many steps and what % of steps to be run on each experts (80/20) here</span><br>n_steps = <span class="hljs-number">40</span><br>high_noise_frac = <span class="hljs-number">0.8</span><br><br>prompt = <span class="hljs-string">&quot;A majestic lion jumping from a big stone at night&quot;</span><br><br><span class="hljs-comment"># run both experts</span><br>image = base(<br>    prompt=prompt,<br>    num_inference_steps=n_steps,<br>    denoising_end=high_noise_frac,<br>    output_type=<span class="hljs-string">&quot;latent&quot;</span>,<br>).images<br>image = refiner(<br>    prompt=prompt,<br>    num_inference_steps=n_steps,<br>    denoising_start=high_noise_frac,<br>    image=image,<br>).images[<span class="hljs-number">0</span>]<br><br>image.save(<span class="hljs-string">&quot;refiner.png&quot;</span>) <br></code></pre></td></tr></table></figure>
<p>GPU: ~ 14GB</p>
<h2 id="demo">Demo</h2>
<ul>
<li><p><strong>Left</strong>: Base model, <strong>Right</strong>: Base+refiner model</p>
<ul>
<li><strong>prompt = "An astronaut is doing Numerical Weather Prediction simulation on Space."</strong></li>
</ul></li>
</ul>
<div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/imchHVz.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/KKiwfNI.png" srcset="/img/loading.gif" lazyload /></div></div></div>
<h1 id="where-does-hugging-faces-transformers-save-models">Where does hugging face's transformers save models?</h1>
<p>The cache location has changed again, and is now <code>~/.cache/huggingface/hub/</code></p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs console"><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">du</span> -sh ~/.cache/huggingface/hub/*</span><br>6.3G	/home/wpsze/.cache/huggingface/hub/models--deepseek-ai--deepseek-vl2-tiny<br>414M	/home/wpsze/.cache/huggingface/hub/models--dslim--bert-base-NER<br>961M	/home/wpsze/.cache/huggingface/hub/models--ecmwf--aifs-single<br>1.7G	/home/wpsze/.cache/huggingface/hub/models--microsoft--DialoGPT-medium<br>172K	/home/wpsze/.cache/huggingface/hub/models--microsoft--Florence-2-large<br>6.7G	/home/wpsze/.cache/huggingface/hub/models--stabilityai--stable-diffusion-xl-base-1.0<br>4.4G	/home/wpsze/.cache/huggingface/hub/models--stabilityai--stable-diffusion-xl-refiner-1.0<br>4.0K	/home/wpsze/.cache/huggingface/hub/version.txt<br>4.0K	/home/wpsze/.cache/huggingface/hub/version_diffusers_cache.txt<br></code></pre></td></tr></table></figure>
<h1 id="web-page">web page</h1>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.volcengine.com/docs/6419/1149863">GPU-基于Diffusers和Gradio搭建SDXL推理应用</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@yvontarbajo/%E9%BA%BB%E7%93%9C%E8%B5%B0%E5%85%A5%E9%AD%94%E6%B3%95%E4%B8%96%E7%95%8C-i-gradio-2e9705f2410e">麻瓜走入魔法世界 I — Gradio</a></li>
<li><a target="_blank" rel="noopener" href="http://localhost:8000/" class="uri">http://localhost:8000/</a></li>
</ul>

    <div class="fold">
      <div class="fold-title fold-info collapsed" data-toggle="collapse" href="#collapse-88d67c90" role="button" aria-expanded="false" aria-controls="collapse-88d67c90">
        <div class="fold-arrow">▶</div>python script
      </div>
      <div class="fold-collapse collapse" id="collapse-88d67c90">
        <div class="fold-content">
          <p>git clone,</p><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs console">git clone https://github.com/AUTOMATIC1111/TorchDeepDanbooru.git<br>cd TorchDeepDanbooru<br>wget https://github.com/AUTOMATIC1111/TorchDeepDanbooru/releases/download/v1/model-resnet_custom_v3.pt<br></code></pre></td></tr></table></figure><p>and web.py,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#!/bin/python</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline,StableDiffusionXLImg2ImgPipeline<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime<br><br><span class="hljs-keyword">from</span> TorchDeepDanbooru <span class="hljs-keyword">import</span> deep_danbooru_model<br><br>MODEL_BASE =  <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span><br>MODEL_REFINER = <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-refiner-1.0&quot;</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Loading model&quot;</span>,MODEL_BASE)<br>base = DiffusionPipeline.from_pretrained(MODEL_BASE, torch_dtype=torch.float16, use_safetensors=<span class="hljs-literal">True</span>, variant=<span class="hljs-string">&quot;fp16&quot;</span>)<br>base.to(<span class="hljs-string">&quot;cuda&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Loading model&quot;</span>,MODEL_REFINER)<br>refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(MODEL_REFINER, text_encoder_2=base.text_encoder_2,vae=base.vae, torch_dtype=torch.float16, use_safetensors=<span class="hljs-literal">True</span>, variant=<span class="hljs-string">&quot;fp16&quot;</span>,)<br>refiner.to(<span class="hljs-string">&quot;cuda&quot;</span>)<br><br><span class="hljs-comment"># Define how many steps and what % of steps to be run on each experts (80/20) here</span><br><span class="hljs-comment"># base-high noise, refiner-low noise</span><br><span class="hljs-comment"># the base model steps = default_n_steps*default_high_noise_frac</span><br>default_n_steps = <span class="hljs-number">40</span><br>default_high_noise_frac = <span class="hljs-number">0.8</span><br>default_num_images =<span class="hljs-number">2</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predit_txt2img</span>(<span class="hljs-params">prompt,negative_prompt,model_selected,num_images,n_steps, high_noise_frac,cfg_scale</span>):<br>    <span class="hljs-comment"># run both experts</span><br>    start = datetime.now()<br><br>    num_images=<span class="hljs-built_in">int</span>(num_images)<br>    n_steps=<span class="hljs-built_in">int</span>(n_steps)<br>    prompt, negative_prompt = [prompt] * num_images, [negative_prompt] * num_images<br>    images_list = []<br>    model_selected = model_selected<br>    high_noise_frac=<span class="hljs-built_in">float</span>(high_noise_frac)<br>    cfg_scale=<span class="hljs-built_in">float</span>(cfg_scale)<br><br>    g = torch.Generator(device=<span class="hljs-string">&quot;cuda&quot;</span>)<br><br>    <span class="hljs-keyword">if</span> model_selected == <span class="hljs-string">&quot;sd-xl-base-1.0&quot;</span> <span class="hljs-keyword">or</span> model_selected == <span class="hljs-string">&quot;sd-xl-base-refiner-1.0&quot;</span>:<br>        images = base(<br>            prompt=prompt,<br>            negative_prompt=negative_prompt,<br>            num_inference_steps=n_steps,<br>            denoising_end=high_noise_frac,<br>            guidance_scale=cfg_scale,<br>            output_type=<span class="hljs-string">&quot;latent&quot;</span> <span class="hljs-keyword">if</span> model_selected == <span class="hljs-string">&quot;sd-xl-base-refiner-1.0&quot;</span> <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;pil&quot;</span>,<br>            generator=g<br>        ).images<br>    <br>    <span class="hljs-keyword">if</span> model_selected == <span class="hljs-string">&quot;sd-xl-base-refiner-1.0&quot;</span>:<br>        images = refiner(<br>            prompt=prompt,<br>            negative_prompt=negative_prompt,<br>            num_inference_steps=n_steps,<br>            denoising_start=high_noise_frac,<br>            guidance_scale=cfg_scale,<br>            image=images,<br>        ).images<br><br>    <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> images:<br>        images_list.append(image)<br><br>    torch.cuda.empty_cache()<br>    <br>    cost_time=(datetime.now()-start).seconds<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;cost time=<span class="hljs-subst">&#123;cost_time&#125;</span>,<span class="hljs-subst">&#123;datetime.now()&#125;</span>&quot;</span>)<br>    <br>    <span class="hljs-keyword">return</span> images_list<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predit_img2img</span>(<span class="hljs-params">prompt, negative_prompt,init_image, model_selected,n_steps, high_noise_frac,cfg_scale,strength</span>):<br>    <br>    start = datetime.now()<br>    prompt = prompt<br>    negative_prompt =negative_prompt<br><br>    model_selected = model_selected<br>    init_image = init_image<br>    n_steps=<span class="hljs-built_in">int</span>(n_steps)<br>    high_noise_frac=<span class="hljs-built_in">float</span>(high_noise_frac)<br>    cfg_scale=<span class="hljs-built_in">float</span>(cfg_scale)<br>    strength=<span class="hljs-built_in">float</span>(strength)<br><br>    <span class="hljs-keyword">if</span> model_selected == <span class="hljs-string">&quot;sd-xl-refiner-1.0&quot;</span>:<br>        images = refiner(<br>            prompt=prompt,<br>            negative_prompt=negative_prompt,<br>            num_inference_steps=n_steps,<br>            denoising_start=high_noise_frac,<br>            guidance_scale=cfg_scale,<br>            strength = strength,<br>            image=init_image,<br>            <span class="hljs-comment"># target_size = (1024, 1024)</span><br>        ).images<br><br>    torch.cuda.empty_cache()<br>    <br>    cost_time=(datetime.now()-start).seconds<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;cost time=<span class="hljs-subst">&#123;cost_time&#125;</span>,<span class="hljs-subst">&#123;datetime.now()&#125;</span>&quot;</span>)<br><br>    <span class="hljs-keyword">return</span> images[<span class="hljs-number">0</span>]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">interrogate_deepbooru</span>(<span class="hljs-params">pil_image, threshold</span>):<br>    threshold =<span class="hljs-number">0.5</span><br>    model = deep_danbooru_model.DeepDanbooruModel()<br>    model.load_state_dict(torch.load(<span class="hljs-string">&#x27;/home/wpsze/ML/huggingface_hub/stable-diffusion-xl-base-1.0/TorchDeepDanbooru/model-resnet_custom_v3.pt&#x27;</span>))<br>    model.<span class="hljs-built_in">eval</span>().half().cuda()<br><br>    pic = pil_image.convert(<span class="hljs-string">&quot;RGB&quot;</span>).resize((<span class="hljs-number">512</span>, <span class="hljs-number">512</span>))<br>    a = np.expand_dims(np.array(pic, dtype=np.float32), <span class="hljs-number">0</span>) / <span class="hljs-number">255</span><br><br>    <span class="hljs-keyword">with</span> torch.no_grad(), torch.autocast(<span class="hljs-string">&quot;cuda&quot;</span>):<br>        x = torch.from_numpy(a).cuda()<br><br>        <span class="hljs-comment"># first run</span><br>        y = model(x)[<span class="hljs-number">0</span>].detach().cpu().numpy()<br><br>        <span class="hljs-comment"># measure performance</span><br>        <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> tqdm.tqdm(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)):<br>            model(x)<br><br>    result_tags_out = []<br>    <span class="hljs-keyword">for</span> i, p <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(y):<br>        <span class="hljs-keyword">if</span> p &gt;= threshold:<br>            result_tags_out.append(model.tags[i])<br>            <span class="hljs-built_in">print</span>(model.tags[i], p)<br><br>    prompt = <span class="hljs-string">&#x27;, &#x27;</span>.join(result_tags_out).replace(<span class="hljs-string">&#x27;_&#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>).replace(<span class="hljs-string">&#x27;:&#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;prompt=<span class="hljs-subst">&#123;prompt&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">return</span> prompt<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">clear_txt2img</span>(<span class="hljs-params">prompt, negative_prompt</span>):<br>    prompt = <span class="hljs-string">&quot;&quot;</span><br>    negative_prompt = <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> prompt, negative_prompt<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">clear_img2img</span>(<span class="hljs-params">prompt, negative_prompt, image_input,image_output</span>):<br>    prompt = <span class="hljs-string">&quot;&quot;</span><br>    negative_prompt = <span class="hljs-string">&quot;&quot;</span><br>    image_input = <span class="hljs-literal">None</span><br>    image_output = <span class="hljs-literal">None</span><br><br>    <span class="hljs-keyword">return</span> prompt, negative_prompt,image_input,image_output<br><br><span class="hljs-keyword">with</span> gr.Blocks(title=<span class="hljs-string">&quot;Stable Diffusion&quot;</span>,theme=gr.themes.Default(primary_hue=gr.themes.colors.blue))<span class="hljs-keyword">as</span> demo:<br>    <br>    <span class="hljs-keyword">with</span> gr.Tab(<span class="hljs-string">&quot;Text-to-Image&quot;</span>): <br>        <span class="hljs-comment"># gr.Markdown(&quot;Stable Diffusion XL Base + Refiner.&quot;)</span><br>        model_selected = gr.Radio([<span class="hljs-string">&quot;sd-xl-base-refiner-1.0&quot;</span>,<span class="hljs-string">&quot;sd-xl-base-1.0&quot;</span>],show_label=<span class="hljs-literal">False</span>, value=<span class="hljs-string">&quot;sd-xl-base-refiner-1.0&quot;</span>)       <br>        <span class="hljs-keyword">with</span> gr.Row():<br>            <span class="hljs-keyword">with</span> gr.Column(scale=<span class="hljs-number">4</span>):<br>                prompt = gr.Textbox(label= <span class="hljs-string">&quot;Prompt&quot;</span>,lines=<span class="hljs-number">3</span>)<br>                negative_prompt = gr.Textbox(label= <span class="hljs-string">&quot;Negative Prompt&quot;</span>,lines=<span class="hljs-number">1</span>)<br>                <span class="hljs-keyword">with</span> gr.Row():<br>                    <span class="hljs-keyword">with</span> gr.Column():                        <br>                        n_steps=gr.Slider(<span class="hljs-number">20</span>, <span class="hljs-number">60</span>, value=default_n_steps, label=<span class="hljs-string">&quot;Steps&quot;</span>, info=<span class="hljs-string">&quot;Choose between 20 and 60&quot;</span>)<br>                        high_noise_frac=gr.Slider(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, value=<span class="hljs-number">0.8</span>, label=<span class="hljs-string">&quot;Denoising Start at&quot;</span>)<br>                    <span class="hljs-keyword">with</span> gr.Column():     <br>                        num_images=gr.Slider(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, value=default_num_images, label=<span class="hljs-string">&quot;Gernerated Images&quot;</span>, info=<span class="hljs-string">&quot;Choose between 1 and 3&quot;</span>) <span class="hljs-comment">#num images=4,A10报显存溢出</span><br>                        cfg_scale=gr.Slider(<span class="hljs-number">1</span>, <span class="hljs-number">20</span>, value=<span class="hljs-number">7.5</span>, label=<span class="hljs-string">&quot;CFG Scale&quot;</span>)<br>            <span class="hljs-keyword">with</span> gr.Column(scale=<span class="hljs-number">1</span>):<br>                <span class="hljs-keyword">with</span> gr.Row():<br>                    txt2img_button = gr.Button(<span class="hljs-string">&quot;Generate&quot;</span>,size=<span class="hljs-string">&quot;sm&quot;</span>)<br>                    clear_button = gr.Button(<span class="hljs-string">&quot;Clear&quot;</span>,size=<span class="hljs-string">&quot;sm&quot;</span>)<br>        gallery = gr.Gallery(label=<span class="hljs-string">&quot;Generated images&quot;</span>, show_label=<span class="hljs-literal">False</span>, elem_id=<span class="hljs-string">&quot;gallery&quot;</span>,columns=<span class="hljs-built_in">int</span>(num_images.value), height=<span class="hljs-number">800</span>,object_fit=<span class="hljs-string">&#x27;fill&#x27;</span>)<br>        <br>        txt2img_button.click(predit_txt2img, inputs=[prompt, negative_prompt, model_selected,num_images,n_steps, high_noise_frac,cfg_scale], outputs=[gallery])<br>        clear_button.click(clear_txt2img, inputs=[prompt, negative_prompt], outputs=[prompt, negative_prompt])<br>    <br>    <span class="hljs-keyword">with</span> gr.Tab(<span class="hljs-string">&quot;Image-to-Image&quot;</span>):  <br>        model_selected = gr.Radio([<span class="hljs-string">&quot;sd-xl-refiner-1.0&quot;</span>],value=<span class="hljs-string">&quot;sd-xl-refiner-1.0&quot;</span>,show_label=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">with</span> gr.Row():<br>            <span class="hljs-keyword">with</span> gr.Column(scale=<span class="hljs-number">1</span>):<br>                prompt = gr.Textbox(label= <span class="hljs-string">&quot;Prompt&quot;</span>,lines=<span class="hljs-number">2</span>)<br>            <span class="hljs-keyword">with</span> gr.Column(scale=<span class="hljs-number">1</span>):            <br>                negative_prompt = gr.Textbox(label= <span class="hljs-string">&quot;Negative Prompt&quot;</span>,lines=<span class="hljs-number">2</span>)<br>        <span class="hljs-keyword">with</span> gr.Row():<br>            <span class="hljs-keyword">with</span> gr.Column(scale=<span class="hljs-number">3</span>):<br>                image_input = gr.Image(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;pil&quot;</span>,height=<span class="hljs-number">512</span>)<br>            <span class="hljs-keyword">with</span> gr.Column(scale=<span class="hljs-number">3</span>):<br>                image_output = gr.Image(height=<span class="hljs-number">512</span>)<br>            <span class="hljs-keyword">with</span> gr.Column(scale=<span class="hljs-number">1</span>):<br>                img2img_deepbooru = gr.Button(<span class="hljs-string">&quot;Interrogate DeepBooru&quot;</span>,size=<span class="hljs-string">&quot;sm&quot;</span>)<br>                <span class="hljs-comment"># img2img_clip = gr.Button(&quot;Interrogate CLIP&quot;,size=&quot;sm&quot;)</span><br>                img2img_button = gr.Button(<span class="hljs-string">&quot;Generate&quot;</span>,size=<span class="hljs-string">&quot;lg&quot;</span>)<br>                clear_button = gr.Button(<span class="hljs-string">&quot;Clear&quot;</span>,size=<span class="hljs-string">&quot;sm&quot;</span>) <br>                                <br>                n_steps=gr.Slider(<span class="hljs-number">20</span>, <span class="hljs-number">60</span>, value=<span class="hljs-number">40</span>, step=<span class="hljs-number">10</span>,label=<span class="hljs-string">&quot;Steps&quot;</span>)<br>                high_noise_frac=gr.Slider(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, value=<span class="hljs-number">0.8</span>, step=<span class="hljs-number">0.1</span>,label=<span class="hljs-string">&quot;Denoising Start at&quot;</span>)<br>                cfg_scale=gr.Slider(<span class="hljs-number">1</span>, <span class="hljs-number">20</span>, value=<span class="hljs-number">7.5</span>, step=<span class="hljs-number">0.1</span>,label=<span class="hljs-string">&quot;CFG Scale&quot;</span>)<br>                strength=gr.Slider(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, value=<span class="hljs-number">0.3</span>,step=<span class="hljs-number">0.1</span>,label=<span class="hljs-string">&quot;Denoising strength&quot;</span>)  <br>       <br>        img2img_deepbooru.click(fn=interrogate_deepbooru, inputs=image_input,outputs=[prompt])<br>        img2img_button.click(predit_img2img, inputs=[prompt, negative_prompt, image_input, model_selected, n_steps, high_noise_frac,cfg_scale,strength], outputs=image_output)<br>        clear_button.click(clear_img2img, inputs=[prompt, negative_prompt, image_input], outputs=[prompt, negative_prompt, image_input,image_output]) <br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    demo.launch(server_name=<span class="hljs-string">&quot;0.0.0.0&quot;</span>, server_port=<span class="hljs-number">8000</span>)<br></code></pre></td></tr></table></figure>
        </div>
      </div>
    </div>
<p><img src="https://i.imgur.com/0AR2q5n.png" srcset="/img/loading.gif" lazyload width="500" /></p>
<p><img src="https://i.imgur.com/5SRHOZj.png" srcset="/img/loading.gif" lazyload /></p>
<h1 id="access-to-model-is-restricted-not-yet">Access to model is restricted (not yet)</h1>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs console">Cannot access gated repo for url https://huggingface.co/stabilityai/stable-diffusion-3.5-large/resolve/main/model_index.json.<br>Access to model stabilityai/stable-diffusion-3.5-large is restricted. You must have access to it and be authenticated to access it. Please log in.<br></code></pre></td></tr></table></figure>
<div class="note note-success">
            <p>huggingface -- sign up -- Access Tokens -- generate token key</p>
          </div>
<p>You need to sign in to huggingface, accept the license agreement on sd 3.5 page, go to settings in your hf profile, find your token and input it in sd next config file.</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs console"><span class="hljs-meta prompt_">$ </span><span class="language-bash">huggingface-cli login</span><br><br>    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|<br>    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|<br>    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|<br>    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|<br>    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|<br><br>    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .<br>Enter your token (input will not be visible): <br>Add token as git credential? (Y/n) n<br>Token is valid (permission: fineGrained).<br>The token `sd` has been saved to /home/wpsze/.cache/huggingface/stored_tokens<br>Your token has been saved to /home/wpsze/.cache/huggingface/token<br>Login successful.<br>The current active token is: `sd`<br></code></pre></td></tr></table></figure>
<p>Then,</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs console">403 Forbidden: Please enable access to public gated repositories in your fine-grained token settings to view this repository..<br>Cannot access content at: https://huggingface.co/stabilityai/stable-diffusion-3.5-large/resolve/main/model_index.json.<br>Make sure your token has the correct permissions.<br></code></pre></td></tr></table></figure>
<h1 id="references">References</h1>
<ol type="1">
<li><a target="_blank" rel="noopener" href="https://soulteary.com/2023/07/29/get-started-with-stability-ai-sdxl-1-0-release-using-docker.html">使用 Docker 快速上手 Stability AI 的 SDXL 1.0 正式版</a></li>
<li><a target="_blank" rel="noopener" href="https://soulteary.com/2022/12/10/play-the-stable-diffusion-model-on-macbook-devices-with-m1-and-m2-chips.html">在搭载 M1 及 M2 芯片 MacBook设备上玩 Stable Diffusion 模型</a></li>
<li><a target="_blank" rel="noopener" href="https://www.volcengine.com/docs/6419/1149863">GPU-基于Diffusers和Gradio搭建SDXL推理应用</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@yvontarbajo/%E9%BA%BB%E7%93%9C%E8%B5%B0%E5%85%A5%E9%AD%94%E6%B3%95%E4%B8%96%E7%95%8C-i-gradio-2e9705f2410e">麻瓜走入魔法世界 I — Gradio</a></li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/ML/" class="category-chain-item">ML</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/AI/" class="print-no-link">#AI</a>
      
        <a href="/tags/ML/" class="print-no-link">#ML</a>
      
        <a href="/tags/pytorch/" class="print-no-link">#pytorch</a>
      
        <a href="/tags/huggingface/" class="print-no-link">#huggingface</a>
      
        <a href="/tags/LLM/" class="print-no-link">#LLM</a>
      
        <a href="/tags/stable-diffusion/" class="print-no-link">#stable-diffusion</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>ML | stable-diffusion</div>
      <div>https://waipangsze.github.io/2025/01/09/ML-stable-diffusion/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>wpsze</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>January 9, 2025</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Updated on</div>
          <div>October 27, 2025</div>
        </div>
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/01/10/ML-stable-video-diffusion-img2vid-xt/" title="ML | stable-video-diffusion-img2vid-xt">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">ML | stable-video-diffusion-img2vid-xt</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/01/08/ML-huggingface-LLM/" title="ML | huggingface">
                        <span class="hidden-mobile">ML | huggingface</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.utils.listenDOMLoaded(function() {
      Fluid.events.registerRefreshCallback(function() {
        if ('mermaid' in window) {
          mermaid.init();
        }
      });
    });
  });
</script>






<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9HL36SZ28R"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9HL36SZ28R');
</script>

    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">

  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  

  <span id="sitetime"></span>
  <script language=javascript>
    function siteTime(){
      window.setTimeout("siteTime()", 1000);
      var seconds = 1000;
      var minutes = seconds * 60;
      var hours = minutes * 60;
      var days = hours * 24;
      var years = days * 365;
      var today = new Date();
      var todayYear = today.getFullYear();
      var todayMonth = today.getMonth()+1;
      var todayDate = today.getDate();
      var todayHour = today.getHours();
      var todayMinute = today.getMinutes();
      var todaySecond = today.getSeconds();
      /* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
      year - 作为date对象的年份，为4位年份值
      month - 0-11之间的整数，做为date对象的月份
      day - 1-31之间的整数，做为date对象的天数
      hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
      minutes - 0-59之间的整数，做为date对象的分钟数
      seconds - 0-59之间的整数，做为date对象的秒数
      microseconds - 0-999之间的整数，做为date对象的毫秒数 */
      var t1 = Date.UTC(2023,04,23,00,00,00); //北京时间2018-2-13 00:00:00
      var t2 = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
      var diff = t2-t1;
      var diffYears = Math.floor(diff/years);
      var diffDays = Math.floor((diff/days)-diffYears*365);
      var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
      var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
      var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
      /*document.getElementById("sitetime").innerHTML=" 已运行"+/*diffYears+" 年 "+*/diffDays+" 天 "+diffHours+" 小时 "+diffMinutes+" 分钟 "+diffSeconds+" 秒";
      document.getElementById("sitetime").innerHTML=" 已運行"+diffYears+" 年 "+diffDays+" 天 ";
    }/*因为建站时间还没有一年，就将之注释掉了。需要的可以取消*/
    siteTime();
  </script>
  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
