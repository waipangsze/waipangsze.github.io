

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=light>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="wpsze">
  <meta name="keywords" content="">
  
    <meta name="description" content="&quot;Attention is all you need&quot; (2017)  Vaswani, A. (2017). Attention is all you need. Advances in Neural Information Processing Systems.   Encoder層和Decoder層內部結構如圖所示。  Encoder具有兩層結構，self-attention和前饋神經網路。">
<meta property="og:type" content="article">
<meta property="og:title" content="ML | Transformer | Attention, FFN, ResNet">
<meta property="og:url" content="https://waipangsze.github.io/2025/01/30/ML-Transformers/index.html">
<meta property="og:site_name" content="wpsze">
<meta property="og:description" content="&quot;Attention is all you need&quot; (2017)  Vaswani, A. (2017). Attention is all you need. Advances in Neural Information Processing Systems.   Encoder層和Decoder層內部結構如圖所示。  Encoder具有兩層結構，self-attention和前饋神經網路。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.imgur.com/m673yGz.png">
<meta property="article:published_time" content="2025-01-30T13:20:00.000Z">
<meta property="article:modified_time" content="2025-02-03T00:32:58.528Z">
<meta property="article:author" content="wpsze">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="ML">
<meta property="article:tag" content="NWP">
<meta property="article:tag" content="ResNet">
<meta property="article:tag" content="RNN">
<meta property="article:tag" content="Transformer">
<meta property="article:tag" content="Attention">
<meta property="article:tag" content="FFN">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://i.imgur.com/m673yGz.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>ML | Transformer | Attention, FFN, ResNet - wpsze</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"waipangsze.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":"F7MK-FcxSomhtc1N3hIUDA"},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=F7MK-FcxSomhtc1N3hIUDA", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', 'F7MK-FcxSomhtc1N3hIUDA');
        });
      }
    </script>
  

  

  

  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>wpsze</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>Links</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/bookmark/" target="_self">
                <i class="iconfont icon-bookmark"></i>
                <span>Bookmarks</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                <span>Docs</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/Physics/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>Physics</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/Maths/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>Maths</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/CFD/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>CFD</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/ML/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>ML</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/Meteorology/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>Meteorology</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/MPAS/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>MPAS</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/monitor/" target="_self">
                    
                    <span>Real Time Monitoring</span>
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About Me</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://i.imgur.com/m673yGz.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="ML | Transformer | Attention, FFN, ResNet"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-01-30 21:20" pubdate>
          January 30, 2025 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          2.4k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          21 mins
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> views
        </span>
        

      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">ML | Transformer | Attention, FFN, ResNet</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="attention-is-all-you-need-2017">"Attention is all you need" (2017)</h1>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">Vaswani, A. (2017). <strong>Attention is all you need</strong>. Advances in Neural Information Processing Systems.</a></li>
</ul>
<div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/MUotlGg.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/swgaC77.png" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/oqquyUc.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/qA7n7K2.png" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/MiCibQL.jpg" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/Ddp94SL.png" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"></div><div class="group-image-row"></div><div class="group-image-row"></div></div>
<p>Encoder層和Decoder層內部結構如圖所示。</p>
<ul>
<li>Encoder具有兩層結構，self-attention和前饋神經網路。 self-attention計算句子中的每個詞都和其他詞的關聯，從而幫助模型更好地理解上下文語義，引入Muti-Head attention後，每個頭關注句子的不同位置，增強了Attention機制關注句子內部單詞之間作用的表達能力。<strong>前饋神經網路為encoder引入非線性變換，增強了模型的擬合能力</strong>。</li>
<li>The encoder is composed of a stack of <span class="math inline">\(N = 6\)</span> identical layers. (<strong>疊6次</strong> !!!)</li>
<li>Decoder接受output輸入的同時接受encoder的輸入，幫助目前節點取得到需要重點關注的內容</li>
<li><strong>縮放因子</strong>的作用是歸一化</li>
<li>FFN的加入引入了非線性(ReLu激活函數)，變換了attention output的空間, 從而增加了模型的表現能力。把FFN去掉模型也是可以用的，但效果差很多了。</li>
<li>在每個block中，最後出現的是Layer Normalization，其作用是規範最佳化空間，加速收斂。</li>
<li>當我們使用梯度下降演算法做最佳化時，我們可能會對輸入資料進行歸一化，但是經過網路層作用後，我們的資料已經不是歸一化的了。隨著網路層數的增加，資料分佈不斷變化，偏差越來越大，導致我們不得不使用更小的學習率來穩定梯度。 Layer Normalization 的作用是確保資料特徵分佈的穩定性，將資料標準化到ReLU活化函數的作用區域，可以使得激活函數更好的發揮作用。<strong>Normalization有兩種方法，Batch Normalization和Layer Normalization</strong>。</li>
<li><strong>Positional Encoding</strong> : 位置資訊編碼位於encoder和decoder的embedding之後，每個block之前。它非常重要，沒有這部分模型就無法運作。 Positional Encoding是transformer的特有機制，彌補了Attention機制無法捕捉sequence中token位置資訊的缺點。Positional Embedding的成分直接疊加於Embedding之上，使得每個token的位置資訊和它的語義資訊(embedding)充分融合，並被傳遞到後續所有經過複雜變換的序列表達中去。
<ul>
<li><strong>提供位置信息</strong>：位置編碼的主要功能是告訴模型每個輸入向量在序列中的具體位置。這對於理解語言中的語法結構和上下文至關重要，因為語言的意義往往依賴於詞語的順序。</li>
<li><strong>數學表達</strong> : 位置編碼通常使用正弦和餘弦函數來生成，這樣可以保證不同位置之間的距離信息。具體公式如下：
<ul>
<li>對於位置 <span class="math inline">\(pos\)</span> 和維度 <span class="math inline">\(i\)</span>： <span class="math display">\[
\text{PE}(pos, 2i) = \sin\left(\frac{pos}{10000^{2i/d_{model}}}\right)
\]</span> <span class="math display">\[
\text{PE}(pos, 2i+1) = \cos\left(\frac{pos}{10000^{2i/d_{model}}}\right)
\]</span> 其中，<span class="math inline">\(d_{model}\)</span> 是模型的維度（例如512），而 <span class="math inline">\(i\)</span> 是當前維度的索引。<strong>這種設計使得每個位置都有一組唯一的向量表示，並且相鄰位置之間的關係可以通過這些向量的相似性來捕捉</strong>!!!。</li>
<li><img src="https://i.imgur.com/A3FBmBf.png" srcset="/img/loading.gif" lazyload width="400" /></li>
<li>句子中的位置獲得相應的位置編碼。例如，在句子 <code>貓坐在墊子上</code> 中，<code>貓</code>的位置編碼將與<code>坐</code>的不同，這樣模型就能夠理解它們之間的順序和關係。</li>
</ul></li>
</ul></li>
<li><strong>Cross Attention</strong>
<ul>
<li>交叉注意力使得模型能夠在處理一個序列時，參考另一個序列的信息。這種機制特別適用於需要同時考慮多個模態或序列的任務，例如機器翻譯、圖像描述生成等。</li>
<li><strong>與自注意力的對比</strong>
<ul>
<li><p><strong>自注意力（Self-Attention）</strong>：主要關注同一序列內部元素之間的關係，允許每個元素關注到其他所有元素。這有助於捕捉長距離依賴關係。</p></li>
<li><strong>交叉注意力</strong>：則專注於兩個不同序列之間的互動，允許模型在生成過程中參考其他序列的信息。</li>
</ul></li>
</ul></li>
<li>Mask 機制
<ul>
<li>mask 表示掩碼，它對某些值進行掩蓋，使其在參數更新時不產生效果。 Transformer 模型裡面涉及兩種 mask，分別是 padding mask 和 sequence mask。其中，padding mask 在所有的 scaled dot-product attention 裡面都需要用到，而 sequence mask 只有在 decoder 的 self-attention 裡面用到。</li>
<li><strong>padding mask</strong>: 因為每個批次輸入序列長度都是不一樣的也就是說，我們要對輸入序列進行對齊。具體來說，就是給在較短的序列後面填滿 0。但是如果輸入的序列太長，則是截取左邊的內容，把多餘的直接捨棄。因為這些填滿的位置，其實是沒什麼意義的，所以我們的attention機制不應該把注意力放在這些位置上，所以我們需要進行一些處理。具體的做法是，把這些位置的值加上一個非常大的負數(負無窮)，這樣的話，經過 softmax，這些位置的機率就會接近0。</li>
<li><strong>Sequence mask</strong>: sequence mask 是為了讓 decoder 不能看見未來的資訊。也就是對於一個序列，在 time_step 為 t 的時刻，我們的解碼輸出應該只能依賴 t 時刻之前的輸出，而不能依賴 t 之後的輸出。因此我們需要想一個辦法，把 t 之後的訊息給隱藏起來。</li>
</ul></li>
<li><strong>Decoder Masked Attention</strong>
<ul>
<li>遮罩注意力機制的<strong>主要目的是在訓練階段防止解碼器（Decoder）利用未來位置的資訊</strong>，確保模型僅基於當前及之前的輸入生成輸出，模擬實際推理時逐步預測的過程。</li>
<li>為遮蔽未來位置，在計算 softmax 前，將注意力分數矩陣的上三角部分（未來位置）設為 <code>-inf</code>，（Upper Triangular Matrix），迫使模型忽略未來資訊</li>
<li><span class="math display">\[
\text{MaskedAttention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}} + M_{\text{mask}}\right)V
\]</span></li>
<li>假設序列長度為 3，遮罩矩陣為： <span class="math display">\[
M_{\text{mask}} = 
\begin{bmatrix}
0 &amp; -\infty &amp; -\infty \\
0 &amp; 0 &amp; -\infty \\
0 &amp; 0 &amp; 0
\end{bmatrix}
\]</span> 此矩陣確保位置 <span class="math inline">\(i\)</span> 僅能關注位置 <span class="math inline">\(j \leq i\)</span>。</li>
<li>解碼器的遮罩多頭注意力（Masked Multi-Head Attention）</li>
<li>以翻譯任務為例，目標序列為 <strong>"貓坐在墊子上"</strong>：
<ul>
<li><strong>訓練階段</strong>：<br />
解碼器輸入為 <code>&lt;BOS&gt; 貓 坐 在 墊子</code>，遮罩確保預測 "坐" 時僅使用 <code>&lt;BOS&gt; 貓</code> 的資訊。</li>
<li><strong>推理階段</strong>：<br />
模型逐步生成輸出（如 <code>貓</code> → <code>坐</code> → <code>在</code>），每一步僅依賴已生成的序列。</li>
</ul></li>
<li>遮罩注意力機制是Transformer解碼器的核心設計之一，<strong>透過數學上的遮罩操作與架構上的因果性約束</strong>，實現高效且準確的序列生成，在機器翻譯、文本生成等任務中表現卓越。</li>
</ul></li>
<li><strong>Residual Network</strong>
<ul>
<li>殘差網絡是深度學習中重要概念。在神經網絡可以收斂的前提下，隨著網絡深度的增加，網絡表現先是逐漸增加至飽和，然後迅速下降，這就是我們經常討論的網絡退化問題。</li>
</ul></li>
<li><strong>Output: The Final Linear and Softmax Layer</strong>
<ul>
<li>線性變換層是一個簡單的全連接神經網絡，它可以把解碼組件產生的向量投射到一個比它大得多的、被稱作對數幾率（logits）的向量裡。接下來的Softmax 層便會把那些分數變成機率（都是正數、上限1.0）。機率最高的單元格被選中，並且它對應的單字被作為這個時間步的輸出。</li>
</ul></li>
</ul>
<div class="note note-primary">
            <ul><li>這裡不得不提一點，雖然論文的名字叫《Attention is All your Need》，但是實際上， FFN and ResNet are also your need。</li><li>研究人員發現FFN 和ResNet 的Skip Connection 無論去掉哪一個，模型都會變得不可用。</li><li>所以說 Attention, FFN, ResNet 可以認為是 Transformers 架構的三駕馬車，缺一不可。</li><li>後續雖然有許多 Transformers 架構的魔改，但真正取得不錯的效果且落地的例子就是修改 FFN 的 MoE 架構。剩下的兩輛馬車，ResNet 幾乎沒辦法修改了，Attention 則在效率和效果之間尋求平衡。</li></ul>
          </div>
<div class="note note-primary">
            <ul><li>MoE : Transformer Feed-forward Layers are Mixtures of Experts 這是劉知遠團隊的論文，其實一直以來，神經網路就存在稀疏活化的現象，也就是在推理的時候，其實只有極小一部分參數參與了計算。這篇論文則透過MoE 的想法來將FFN 層拆分成了多個專家，並且新增了一個路由模組來確定推理的時候來掛哪個專家的門診：）這麼做之後，在提升推理速度的同時，效果仍能維持原來的95%以上。挺有價值的工作，大模型上也可以這麼做一把。</li></ul>
          </div>
<div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/T5yqKkc.gif" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/cpdMrRR.gif" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/0jAGUu9.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/iAPvqC1.png" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"></div><div class="group-image-row"></div><div class="group-image-row"></div><div class="group-image-row"></div></div>
<ul>
<li>After finishing the encoding phase, we begin the decoding phase. Each step in the decoding phase outputs an element from the output sequence (the English translation sentence in this case).</li>
<li>The following steps repeat the process until a special symbol is reached indicating the transformer decoder has completed its output.</li>
<li>The output of each step is fed to the bottom decoder in the next time step, and the decoders bubble up their decoding results just like the encoders did.</li>
<li>And just like we did with the encoder inputs, we embed and add positional encoding to those decoder inputs to indicate the position of each word.</li>
</ul>
<h2 id="linear-classifier-and-final-softmax-for-output-probabilitiesr">Linear Classifier and Final Softmax for Output Probabilitiesr</h2>
<ul>
<li>The decoder stack outputs a vector of floats. How do we turn that into a word? That’s the job of the final Linear layer which is followed by a Softmax Layer.</li>
<li>The Linear layer is a simple fully connected neural network that projects the vector produced by the stack of decoders, into a much, much larger vector called a logits vector.</li>
<li>Let’s assume that our model knows <strong>10,000 unique English words (our model’s “output vocabulary”)</strong> that it’s learned from its training dataset. This would make the <strong>logits vector 10,000 cells wide</strong> – each cell corresponding to the score of a unique word. That is how we interpret the output of the model followed by the Linear layer.</li>
<li>The softmax layer then turns those scores into probabilities (all positive, all add up to 1.0). The cell with the highest probability is chosen, and the word associated with it is produced as the output for this time step.</li>
</ul>
<div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/c2XOwSF.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/7Q5Offp.png" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"></div><div class="group-image-row"></div><div class="group-image-row"></div><div class="group-image-row"></div><div class="group-image-row"></div></div>
<iframe width="560" height="315" src="https://www.youtube.com/embed/zxQyTK8quyY" title="Transformer Neural Networks, ChatGPT&#39;s foundation, Clearly Explained!!!" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
</iframe>
<iframe width="560" height="315" src="https://www.youtube.com/embed/bQ5BoolX9Ag" title="Decoder-Only Transformers, ChatGPTs specific Transformer, Clearly Explained!!!" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
</iframe>
<h1 id="input-as-vectors-for-a-transformer-model">Input as vectors for a Transformer model</h1>
<p>To prepare input as vectors for a Transformer model, the following steps are typically followed:</p>
<h2 id="tokenization">1. <strong>Tokenization</strong></h2>
<p>The first step involves breaking down the input text into smaller units called tokens. This can be done using various tokenization strategies, such as word-level, subword-level (like Byte Pair Encoding), or character-level tokenization. Each token corresponds to a unique identifier in the vocabulary.</p>
<h2 id="embedding">2. <strong>Embedding</strong></h2>
<p>Once the text is tokenized, each token is converted into a dense vector representation through an embedding layer. This process maps tokens to continuous vector spaces, allowing the model to capture semantic relationships between words. The embedding can be learned during training or pre-trained embeddings (like Word2Vec or GloVe) can be used.</p>
<ul>
<li><strong>Learned Embeddings</strong>: In the original Transformer paper, Vaswani et al. (2017) proposed using learned embeddings, meaning that the model learns to represent tokens as vectors during training.</li>
</ul>
<h2 id="positional-encoding">3. <strong>Positional Encoding</strong></h2>
<p>Since Transformers do not inherently understand the order of tokens due to their parallel processing capability, positional encodings are added to the embeddings to provide information about the position of each token in the sequence. The positional encoding is typically a fixed function based on sine and cosine functions of different frequencies.</p>
<ul>
<li>The positional encoding is added to the input embeddings, resulting in a combined representation that retains both the content and positional information.</li>
</ul>
<h2 id="summary-of-input-preparation-steps">Summary of Input Preparation Steps</h2>
<ol type="1">
<li><strong>Tokenization</strong>: Split text into tokens.</li>
<li><strong>Embedding</strong>: Convert tokens into dense vectors.</li>
<li><strong>Positional Encoding</strong>: Add positional information to embeddings.</li>
<li><strong>Feed into Encoder</strong>: Use combined vectors as input for the Transformer encoder.</li>
</ol>
<p><img src="https://i.imgur.com/WQyQ5Pe.png" srcset="/img/loading.gif" lazyload width="600" /></p>
<h1 id="自注意力機制-self-attention">自注意力機制 (Self-attention)</h1>
<h2 id="core-components">Core Components</h2>
<p>In self-attention, we define three matrices:</p>
<ul>
<li><strong>Query (Q)</strong>: Represents the elements for which we want to compute attention scores.</li>
<li><strong>Key (K)</strong>: Represents the elements that will be compared against the queries.</li>
<li><strong>Value (V)</strong>: Represents the actual information we want to aggregate based on the attention scores.</li>
</ul>
<p>To compute these matrices from an input embedding matrix <span class="math inline">\(X\)</span> (of shape <span class="math inline">\(L \times D\)</span>, where <span class="math inline">\(L\)</span> is the number of words and <span class="math inline">\(D\)</span> is the embedding dimension), we use learned weight matrices <span class="math inline">\(W_Q\)</span>, <span class="math inline">\(W_K\)</span>, and <span class="math inline">\(W_V\)</span>:</p>
<p><span class="math display">\[
Q = X W_Q
\]</span> <span class="math display">\[
K = X W_K
\]</span> <span class="math display">\[
V = X W_V
\]</span></p>
<h2 id="attention-score-calculation">Attention Score Calculation</h2>
<p>The self-attention mechanism computes attention scores using the following steps:</p>
<ol type="1">
<li><p><strong>Dot Product</strong>: Calculate the dot product of the query and key matrices: <span class="math display">\[
\text{Attention Scores} = QK^T
\]</span> This results in a matrix where each entry indicates the similarity between queries and keys.</p></li>
<li><p><strong>Scaling</strong>: To stabilize gradients during training, we scale the dot product by the square root of the dimension of the key vectors <span class="math inline">\(d_k\)</span>: <span class="math display">\[
S = \frac{QK^T}{\sqrt{d_k}}
\]</span></p></li>
<li><p><strong>Softmax</strong>: Apply the softmax function to convert these scores into probabilities: <span class="math display">\[
A = \text{softmax}(S)
\]</span> This ensures that the attention scores sum to 1 across each row, effectively normalizing them.</p></li>
<li><p><strong>Weighted Sum</strong>: Finally, compute the output by taking a weighted sum of the value vectors based on the attention scores: <span class="math display">\[
O = AV
\]</span> Here, <span class="math inline">\(O\)</span> is the output matrix representing aggregated information from <span class="math inline">\(V\)</span> based on how much focus each query gives to each value.</p></li>
</ol>
<h3 id="complete-self-attention-equation">Complete Self-Attention Equation</h3>
<p>Combining these steps, we can express self-attention as: <span class="math display">\[
O = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\]</span></p>
<h2 id="multi-head-attention">Multi-Head Attention</h2>
<p>In practice, transformers often use multi-head attention, which allows the model to jointly attend to information from different representation subspaces. The output for each head is computed independently and then concatenated: <span class="math display">\[
O = W_o [H_1; H_2; ...; H_M]
\]</span> where each head <span class="math inline">\(H_i\)</span> is calculated as: <span class="math display">\[
H_i = \text{softmax}\left(\frac{W_k^{(i)}Q(W_q^{(i)})^T}{\sqrt{d_k}}\right)W_v^{(i)}V
\]</span></p>
<p>Here, <span class="math inline">\(W_q^{(i)}, W_k^{(i)}, W_v^{(i)}\)</span> are learned weight matrices for each head, and <span class="math inline">\(W_o\)</span> is a final linear transformation applied after concatenating all heads.</p>
<div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/m673yGz.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/1xy5F9F.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/d6LS6YQ.png" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/L8t2LFA.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/JL92Jfv.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/uNcguro.png" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/9oxhFT8.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/AzOhXvb.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/36lKeEY.png" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/RxJGBEk.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/vu4JQUO.png" srcset="/img/loading.gif" lazyload /></div></div></div>
<iframe width="560" height="315" src="https://www.youtube.com/embed/hYdO9CscNes" title="【機器學習2021】自注意力機制 (Self-attention) (上)" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
</iframe>
<iframe width="560" height="315" src="https://www.youtube.com/embed/gmsMY5kc-zw" title="【機器學習2021】自注意力機制 (Self-attention) (下)" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
</iframe>
<h1 id="cross-attention">Cross-Attention</h1>
<div class="note note-primary">
            <p>在 cross attention 的基礎上, 提出了 self-attention</p>
          </div>
<div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/kUDX4jY.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/LfWgMKb.png" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"></div><div class="group-image-row"></div><div class="group-image-row"></div></div>
<h1 id="references">References</h1>
<ol type="1">
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/596771388/answer/3459193587">为什么我还是无法理解transformer？ - 看图学的回答 - 知乎 ( <strong>推薦 </strong> )</a></li>
<li><a target="_blank" rel="noopener" href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer ( <strong>推薦 </strong> )</a></li>
<li><a target="_blank" rel="noopener" href="https://goyalpramod.github.io/blogs/Transformers_laid_out/">Transformers Laid Out | Pramod's Blog ( <strong>推薦 </strong> )</a></li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/362131975/answer/3360076979">transformer的细节到底是怎么样的？ - 亚东的回答 - 知乎</a></li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/362131975/answer/3039107481">transformer的细节到底是怎么样的？ - Hao Bai的回答 - 知乎</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/311156298">Transformer - Attention is all you need</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/46990010">论文解读:Attention is All you need</a></li>
<li><a target="_blank" rel="noopener" href="https://deepgram.com/learn/visualizing-and-explaining-transformer-models-from-the-ground-up">Visualizing and Explaining Transformer Models From the Ground Up</a></li>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=n9TlOhRjYoc&amp;ab_channel=Hung-yiLee">【機器學習2021】Transformer (上)</a></li>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=N6aRv06iv2g&amp;ab_channel=Hung-yiLee">【機器學習2021】Transformer (下)</a></li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/ML/" class="category-chain-item">ML</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/AI/" class="print-no-link">#AI</a>
      
        <a href="/tags/ML/" class="print-no-link">#ML</a>
      
        <a href="/tags/NWP/" class="print-no-link">#NWP</a>
      
        <a href="/tags/ResNet/" class="print-no-link">#ResNet</a>
      
        <a href="/tags/RNN/" class="print-no-link">#RNN</a>
      
        <a href="/tags/Transformer/" class="print-no-link">#Transformer</a>
      
        <a href="/tags/Attention/" class="print-no-link">#Attention</a>
      
        <a href="/tags/FFN/" class="print-no-link">#FFN</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>ML | Transformer | Attention, FFN, ResNet</div>
      <div>https://waipangsze.github.io/2025/01/30/ML-Transformers/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>wpsze</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>January 30, 2025</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Updated on</div>
          <div>February 3, 2025</div>
        </div>
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/01/30/ML-DeepSeek/" title="ML | DeepSeek">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">ML | DeepSeek</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/01/30/ML-Frequentist-and-Bayesian/" title="ML | Frequentist and Bayesian (頻率派 和 貝葉斯派)">
                        <span class="hidden-mobile">ML | Frequentist and Bayesian (頻率派 和 貝葉斯派)</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.utils.listenDOMLoaded(function() {
      Fluid.events.registerRefreshCallback(function() {
        if ('mermaid' in window) {
          mermaid.init();
        }
      });
    });
  });
</script>






<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9HL36SZ28R"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9HL36SZ28R');
</script>

    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">

  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  

  <span id="sitetime"></span>
  <script language=javascript>
    function siteTime(){
      window.setTimeout("siteTime()", 1000);
      var seconds = 1000;
      var minutes = seconds * 60;
      var hours = minutes * 60;
      var days = hours * 24;
      var years = days * 365;
      var today = new Date();
      var todayYear = today.getFullYear();
      var todayMonth = today.getMonth()+1;
      var todayDate = today.getDate();
      var todayHour = today.getHours();
      var todayMinute = today.getMinutes();
      var todaySecond = today.getSeconds();
      /* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
      year - 作为date对象的年份，为4位年份值
      month - 0-11之间的整数，做为date对象的月份
      day - 1-31之间的整数，做为date对象的天数
      hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
      minutes - 0-59之间的整数，做为date对象的分钟数
      seconds - 0-59之间的整数，做为date对象的秒数
      microseconds - 0-999之间的整数，做为date对象的毫秒数 */
      var t1 = Date.UTC(2023,04,23,00,00,00); //北京时间2018-2-13 00:00:00
      var t2 = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
      var diff = t2-t1;
      var diffYears = Math.floor(diff/years);
      var diffDays = Math.floor((diff/days)-diffYears*365);
      var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
      var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
      var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
      /*document.getElementById("sitetime").innerHTML=" 已运行"+/*diffYears+" 年 "+*/diffDays+" 天 "+diffHours+" 小时 "+diffMinutes+" 分钟 "+diffSeconds+" 秒";
      document.getElementById("sitetime").innerHTML=" 已運行"+diffYears+" 年 "+diffDays+" 天 ";
    }/*因为建站时间还没有一年，就将之注释掉了。需要的可以取消*/
    siteTime();
  </script>
  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
