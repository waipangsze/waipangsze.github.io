---
layout: post
title: ML | DeepSeek
categories: ML
tags: [NWP, ML, AI, deepseek]
author: wpsze
date: 2025-01-30 21:22:00
math: true
mathjax: true
mathjax_autoNumber: true
mermaid: true
index_img: https://i.imgur.com/kZIc53N.png
banner_img: https://i.imgur.com/kZIc53N.png
---

DeepSeek是一家中國人工智能公司，成立於2023年7月，總部位於浙江省杭州市。該公司專注於開發開源的大型語言模型（LLMs），並由對沖基金High-Flyer全資擁有，該基金由梁文峰共同創辦，梁文峰同時擔任公司的首席執行官。DeepSeek因其在推理任務上的表現與OpenAI的ChatGPT相當，但開發成本和資源消耗卻僅為其一小部分而受到廣泛關注。

# 本地部署

## Ollama

我們可以透過Ollama來進行安裝

- Ollama 官方版：<https://ollama.com/>
  - `curl -fsSL https://ollama.com/install.sh | sh`
  - Ollama 是一個開源軟體，讓使用者可以在自己的硬體上運行、創建和分享大型語言模型服務。這個平台適合希望在本地端運行模型的使用者，因為它不僅可以保護隱私，還允許用戶透過命令行介面輕鬆地設置和互動。Ollama 支援包括 Llama 2 和 Mistral 等多種模型，並提供彈性的客製化選項，例如從其他格式導入模型並設置運行參數。
- Web UI 控制端: [Page Assist - A Web UI for Local AI Models | Chrome Extension](https://chromewebstore.google.com/detail/page-assist-%E6%9C%AC%E5%9C%B0-ai-%E6%A8%A1%E5%9E%8B%E7%9A%84-web/jfgfiigpkhlkbnfnbobbkinehhfdhndo)

## ollama where is model stored

- macOS: `~/.ollama/models`
- Linux: `/usr/share/ollama/.ollama/models`
- Windows: `C:\Users<username>.ollama\models`

## Examples

- The Llama 3.2 1B and 3B models support context length of 128K tokens and are state-of-the-art in their class for on-device use cases like summarization, instruction following, and rewriting tasks running locally at the edge. These models are enabled on day one for Qualcomm and MediaTek hardware and optimized for Arm processors.

{% gi 4 2-2 %}
![](https://i.imgur.com/EhgPLta.png)
![](https://i.imgur.com/9Px50B2.png)
![](https://i.imgur.com/3ki4mkk.png)
![](https://i.imgur.com/W9MzN7v.png)
{% endgi %}

## Distilled models

DeepSeek team has demonstrated that the reasoning patterns of larger models can be distilled into smaller models, resulting in better performance compared to the reasoning patterns discovered through RL on small models.

Below are the models created via fine-tuning against several dense models widely used in the research community using reasoning data generated by DeepSeek-R1. The evaluation results demonstrate that the distilled smaller dense models perform exceptionally well on benchmarks.

```console
# 1.5B Qwen DeepSeek R1
ollama run deepseek-r1:1.5b

#7B Qwen DeepSeek R1
ollama run deepseek-r1:7b

# 8B Llama DeepSeek R1
ollama run deepseek-r1:8b

# 14B Qwen DeepSeek R1
ollama run deepseek-r1:14b

# 32B Qwen DeepSeek R1
ollama run deepseek-r1:32b

# 70B Llama DeepSeek R1
ollama run deepseek-r1:70b
```

{% gi 5 2-2-1 %}
![](https://i.imgur.com/j0QwgGs.png)
![](https://i.imgur.com/ypBX0bL.png)
![](https://i.imgur.com/Jq9gqaJ.png)
![](https://i.imgur.com/knX3TwB.png)
![](https://i.imgur.com/SyCFPAZ.png)
{% endgi %}

## Model Downloads

- DeepSeek-R1

| Model | #Total Params| #Activated Params | Context Length | Download |
|:----------------:|:--------:|:------------:|:----------:|:-------------:|
| DeepSeek-R1-Zero | 671B | 37B | 128k | <https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero> |
| DeepSeek-R1 | 671B |  37B | 128k | <https://huggingface.co/deepseek-ai/DeepSeek-R1> |

DeepSeek-R1-Zero & DeepSeek-R1 are trained based on DeepSeek-V3-Base. For more details regarding the model architecture, please refer to [DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3) repository.

# References

1. [本地部署 DeepSeek-R1 大模型！免费开源，媲美OpenAI-o1能力](https://www.freedidi.com/18341.html)
2. [ollama | deepseek-r1](https://ollama.com/library/deepseek-r1:1.5b)
3. [huggingface | DeepSeek-R1-Distill-Qwen-1.5B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B)
4. [Day 03】Ollama UI 本機建置](https://ithelp.ithome.com.tw/m/articles/10343826)
5. [Llama 3.2: Revolutionizing edge AI and vision with open, customizable models](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/)
6. [ollama | llama3.2](https://ollama.com/library/llama3.2)
