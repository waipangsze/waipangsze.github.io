

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=light>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="wpsze">
  <meta name="keywords" content="">
  
    <meta name="description" content="Diffusion Models Diffusion Models are generative models, meaning that they are used to generate data similar to the data on which they are trained. Fundamentally, Diffusion Models work by destroying t">
<meta property="og:type" content="article">
<meta property="og:title" content="ML | Diffusion Models (Denoising diffusion probabilistic models)">
<meta property="og:url" content="https://waipangsze.github.io/2024/12/15/ML-Diffusion-Models/index.html">
<meta property="og:site_name" content="wpsze">
<meta property="og:description" content="Diffusion Models Diffusion Models are generative models, meaning that they are used to generate data similar to the data on which they are trained. Fundamentally, Diffusion Models work by destroying t">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.imgur.com/ArrrokC.png">
<meta property="article:published_time" content="2024-12-15T03:55:00.000Z">
<meta property="article:modified_time" content="2025-02-03T00:32:58.512Z">
<meta property="article:author" content="wpsze">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="ML">
<meta property="article:tag" content="pytorch">
<meta property="article:tag" content="Diffusion">
<meta property="article:tag" content="UNet">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://i.imgur.com/ArrrokC.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>ML | Diffusion Models (Denoising diffusion probabilistic models) - wpsze</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"waipangsze.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":"F7MK-FcxSomhtc1N3hIUDA"},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=F7MK-FcxSomhtc1N3hIUDA", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', 'F7MK-FcxSomhtc1N3hIUDA');
        });
      }
    </script>
  

  

  

  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>wpsze</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>Links</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/bookmark/" target="_self">
                <i class="iconfont icon-bookmark"></i>
                <span>Bookmarks</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                <span>Docs</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/Physics/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>Physics</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/Maths/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>Maths</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/CFD/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>CFD</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/ML/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>ML</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/Meteorology/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>Meteorology</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/MPAS/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>MPAS</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/PALM/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>PALM</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/monitor/" target="_self">
                    
                    <span>Real Time Monitoring</span>
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About Me</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://i.imgur.com/ArrrokC.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="ML | Diffusion Models (Denoising diffusion probabilistic models)"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-12-15 11:55" pubdate>
          December 15, 2024 am
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          2.5k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          21 mins
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> views
        </span>
        

      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">ML | Diffusion Models (Denoising diffusion probabilistic models)</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="diffusion-models">Diffusion Models</h1>
<p>Diffusion Models are <strong>generative models</strong>, meaning that they are used to generate data similar to the data on which they are trained. Fundamentally, <strong>Diffusion Models work by destroying training data through the successive addition of Gaussian noise, and then learning to recover the data by reversing this noising process</strong>. After training, we can use the Diffusion Model to generate data by simply passing randomly sampled noise through the learned denoising process.</p>
<p>More specifically, a Diffusion Model is a <strong>latent variable model</strong> which maps to the latent space <strong>using a fixed Markov chain</strong>. This chain gradually adds noise to the data in order to obtain the approximate posterior <span class="math inline">\(q(x_1:T|x_0)\)</span>, where <span class="math inline">\(x_1, ..., x_T\)</span> are the latent variables with the same dimensionality as <span class="math inline">\(x_0\)</span>. In the figure below, we see such a Markov chain manifested for image data.</p>
<p>Ultimately, the image is asymptotically transformed to pure Gaussian noise. The goal of training a diffusion model is to learn the <strong>reverse process</strong>. By traversing backwards along this chain, we can generate new data.</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf">Ho, Jonathan, Ajay Jain, and Pieter Abbeel. "Denoising diffusion probabilistic models." Advances in neural information processing systems 33 (2020): 6840-6851.</a></li>
</ul>
<p><img src="https://i.imgur.com/BOHjnCW.png" srcset="/img/loading.gif" lazyload /> <img src="https://i.imgur.com/ArrrokC.png" srcset="/img/loading.gif" lazyload /></p>
<h2 id="training">Training</h2>
<ul>
<li>Loss function: <strong>Kullback-Leibler (KL) Divergences</strong>. The KL Divergence is an asymmetric statistical distance measure of how much one probability distribution P differs from a reference distribution Q.</li>
</ul>
<p><img src="https://i.imgur.com/AGYXOQO.png" srcset="/img/loading.gif" lazyload /> <img src="https://i.imgur.com/EslrwLZ.png" srcset="/img/loading.gif" lazyload /></p>
<p>在擴散模型中，<strong>反向過程</strong>是學習數據分布的核心機制。以下是對這一過程的詳細闡述：</p>
<h3 id="反向過程的定義">1. <strong>反向過程的定義</strong></h3>
<p>反向過程是指從一個完全噪聲化的樣本逐步去噪，以恢復出原始數據的過程。這個過程通常是在採樣階段進行，目標是從最終的噪聲數據 <span class="math inline">\(x_T\)</span> 開始，通過一系列逆向步驟，得到無噪聲的原始數據 <span class="math inline">\(x_0\)</span>。</p>
<h3 id="前向過程與反向過程">2. <strong>前向過程與反向過程</strong></h3>
<ul>
<li><p><strong>前向過程</strong>是將數據逐步添加噪聲，形成一系列帶噪聲的樣本。數學上，這個過程可以表示為： <span class="math display">\[
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t I)
\]</span> 其中 <span class="math inline">\(\beta_t\)</span> 是時間步 <span class="math inline">\(t\)</span> 的噪聲參數。</p></li>
<li><p><strong>反向過程</strong>則是從噪聲逐步去除，以恢復原始數據。通常假設為條件高斯分布： <span class="math display">\[
p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
\]</span> <div class="note note-primary">
            <p>這裡 <span class="math inline">\(\mu_\theta\)</span> 和 <span class="math inline">\(\Sigma_\theta\)</span> 是由神經網絡學習得到的 <strong>均值</strong> 和 <strong>協方差</strong>。</p>
          </div></p></li>
</ul>
<h3 id="學習反向過程">3. <strong>學習反向過程</strong></h3>
<p>為了學習反向過程，模型需要通過神經網絡近似條件概率分布 <span class="math inline">\(p_\theta(x_{t-1} | x_t)\)</span>。具體步驟如下：</p>
<ul>
<li><p><strong>初始化</strong>：從標準正態分布 <span class="math inline">\(N(0, I)\)</span> 中隨機抽取初始樣本 <span class="math inline">\(x_T\)</span>。</p></li>
<li><strong>逐步去噪</strong>：從時間步 <span class="math inline">\(T\)</span> 開始，逐步向前推進到時間步 <span class="math inline">\(1\)</span>，在每個時間步 <span class="math inline">\(t\)</span> 中進行以下操作：
<ul>
<li>抽取噪聲 <span class="math inline">\(z\)</span>，當 <span class="math inline">\(t &gt; 1\)</span> 時，從標準正態分布中抽取。</li>
<li>使用 <strong>參數化的均值和協方差進行去噪</strong>： <span class="math display">\[
x_{t-1} = \frac{1}{\sqrt{\alpha_t}}(x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t)) + \sigma_t z
\]</span> 其中 <span class="math inline">\(\alpha_t\)</span> 和 <span class="math inline">\(\bar{\alpha}_t\)</span> 是預定義的噪聲參數，<span class="math inline">\(\epsilon_\theta(x_t, t)\)</span> 是 <strong>神經網絡預測的噪聲</strong>，<span class="math inline">\(\sigma_t\)</span> 是調整噪聲幅度的參數。</li>
</ul></li>
</ul>
<h3 id="目標函數">4. <strong>目標函數</strong></h3>
<p>為了優化神經網絡，模型通過最小化負對數似然來學習反向過程。可以使用變分下界（ELBO）來表示損失函數： <span class="math display">\[
L = L_0 + L_1 + ... + L_T
\]</span> 其中每項損失 <span class="math inline">\(L_t\)</span> 實際上是兩個高斯分布之間的 <strong>KL散度</strong> ，可以明確地寫為相對於均值的L2損失。</p>
<h3 id="總結">5. <strong>總結</strong></h3>
<p>通過上述步驟，擴散模型能夠有效地學習到數據的複雜分布。<strong>在訓練完成後，可以從標準正態分布中隨機抽取一個噪聲圖像，然後利用學到的反向過程將其轉化為與訓練數據相似的新圖像</strong>。這種方法在圖像生成、音頻合成等領域展示了強大的應用潛力。</p>
<h1 id="details">Details</h1>
<div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/JMP2TcX.png" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"></div><div class="group-image-row"></div><div class="group-image-row"></div><div class="group-image-row"></div><div class="group-image-row"></div></div>
<h2 id="重參數化技巧-reparameterization-trick">重參數化技巧 (Reparameterization trick)</h2>
<p>重參數化技巧在許多工作 (VAE) 中有所引用。如果我們要從某個分佈中隨機取樣 (高斯分佈) 一個樣本，這個過程是無法反傳梯度的。而這個經由高斯雜訊取樣得到 <span class="math inline">\(x_t\)</span> 的過程在diffusion中到處都是，因此我們需要透過重參數技巧來使得他可微。最通常的做法是吧隨機性透過一個獨立的隨機變數 <span class="math inline">\((\epsilon)\)</span> 引導過去。舉個例子，如果要從高斯分佈 <span class="math inline">\(z\sim\mathcal{N}(z;\mu_\theta,\sigma_\theta^2\mathbf{I})\)</span> 取樣一個 <span class="math inline">\(z\)</span>,我們可以寫成：</p>
<p><span class="math display">\[
z=\mu_\theta+\sigma_\theta\odot\epsilon,\epsilon\sim\mathcal{N}(0,\mathbf{I})
\]</span></p>
<p>上式的z依舊是有隨機性的，且滿足平均值為 <span class="math inline">\(\mu_\theta\)</span> 變異數為 <span class="math inline">\(\sigma_\theta^2\)</span> 的高斯分佈。這裡的 <span class="math inline">\(\mu_\theta\)</span> ,<span class="math inline">\(\sigma_\theta^2\)</span>可以是由參數 <span class="math inline">\(\theta\)</span> 的神經網路推論得到的。整個「採樣」過程依舊梯度可導，隨機性被轉嫁到了<span class="math inline">\(\epsilon\)</span>上。</p>
<h2 id="forward-diffusion-process">Forward Diffusion Process</h2>
<h3 id="任意時刻的x_t可以由x_0和beta表示">任意時刻的<span class="math inline">\(x_t\)</span>可以由<span class="math inline">\(x_0\)</span>和<span class="math inline">\(\beta\)</span>表示</h3>
<figure>
<img src="https://i.imgur.com/JtK0R8X.png" srcset="/img/loading.gif" lazyload alt="Forward Diffusion Process - add noise to the image" width="600" /><figcaption>Forward Diffusion Process - add noise to the image</figcaption>
</figure>
<p>透過這個 Reparameterization trick，我們可以將取樣影像 <span class="math inline">\(x_t\)</span> 表示如下：</p>
<p><span class="math display">\[
\begin{align}
z &amp;= \mu + \sigma \epsilon \qquad ;\epsilon \sim N(0,I)\\
x_t &amp;= \sqrt{1-\beta_t} x_{t-1} + \sqrt{\beta_t} \epsilon_{t-1} \\
&amp;= \sqrt{a_t} x_{t-1} + \sqrt{1 - a_t} \epsilon_{t-1} \\
\end{align}
\]</span></p>
<p>能夠透過 <span class="math inline">\(x_0\)</span> 和 <span class="math inline">\(\beta\)</span> 快速得到 <span class="math inline">\(x_t\)</span> 對後續 diffusion model 的推論和推導有巨大作用。</p>
<div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://i.imgur.com/dYILzWB.png" srcset="/img/loading.gif" lazyload /></div><div class="group-image-wrap"><img src="https://i.imgur.com/lpFiGtT.png" srcset="/img/loading.gif" lazyload /></div></div><div class="group-image-row"></div><div class="group-image-row"></div><div class="group-image-row"></div><div class="group-image-row"></div><div class="group-image-row"></div></div>
<div class="note note-primary">
            <p>現在我們可以使用這個公式在任何時間步直接取樣 <span class="math inline">\(x_t\)</span>，這使得 Forward Diffusion Process 更快, <span class="math display">\[x_t = \sqrt{1-\bar{\alpha}_t} x_{0} + \sqrt{1-\bar{\alpha}_t} \epsilon\]</span></p>
          </div>
<h2 id="reverse-diffusion-process">Reverse Diffusion Process</h2>
<p><img src="https://i.imgur.com/2g9HXta.png" srcset="/img/loading.gif" lazyload width="600" /></p>
<div class="note note-primary">
            <p>Unlike the forward process, we cannot use <span class="math inline">\(q(x_{t-1}|x_t)\)</span> to reverse the noise since it is <strong>intractable</strong> (<strong>uncomputable</strong>).</p>
          </div>
<ul>
<li>Thus we need to train a neural network <span class="math inline">\(p_\theta(x_{t-1}|x_t)\)</span> to approximate <span class="math inline">\(q(x_{t-1}|x_t)\)</span> .</li>
<li>The approximation <span class="math inline">\(p_\theta(x_{t-1}|x_t)\)</span> follows <strong>a normal distribution</strong> and <strong>its mean and variance</strong> are set as follows</li>
</ul>
<p><span class="math display">\[
\begin{align}
\mu_\theta &amp;:= \tilde{\mu}_t(x_t, x_0)\\
\Sigma_\theta &amp;:= \tilde{\beta}_t \mathbf{I}
\end{align}
\]</span></p>
<p><strong>Loss Function</strong>: We can define our loss as a <strong>Negative Log-Likelihood</strong>:</p>
<p><img src="https://i.imgur.com/i69Cxwx.png" srcset="/img/loading.gif" lazyload width="400" /></p>
<p><strong>This setup is very similar to the one in VAE</strong>. instead of optimizing the intractable loss function itself, we can optimize the <strong>Variational Lower Bound</strong>.</p>
<p><img src="https://i.imgur.com/GAvchZh.png" srcset="/img/loading.gif" lazyload width="700" /></p>
<ol type="1">
<li><span class="math inline">\(L_T\)</span> Constant term</li>
<li><span class="math inline">\(L_{t-1}\)</span> Stepwise denoising term
<ol type="1">
<li><img src="https://i.imgur.com/672L1Hw.png" srcset="/img/loading.gif" lazyload width="600" /></li>
<li>To approximate the target denoising step <span class="math inline">\(q\)</span>, we only need to approximate its mean using a neural network. So <strong>we set the approximated mean</strong> <span class="math inline">\(\mu_\theta\)</span> to be in the <strong>same form as the target mean</strong> <span class="math inline">\(\tilde{\mu}_t\)</span> (with <strong>a learnable neural network</strong> <span class="math inline">\(\epsilon_\theta\)</span>)</li>
<li>Experimentally, better results can be achieved by ignoring the weighting term and simply comparing the target and predicted noises with MSE.</li>
<li>So, it turns out that to approximate the desired denoising step <span class="math inline">\(q\)</span>, we just need to approximate the noise <span class="math inline">\(\epsilon_t\)</span> using a neural network <span class="math inline">\(\epsilon_\theta\)</span>.</li>
</ol></li>
<li><span class="math inline">\(L0\)</span> Reconstruction term
<ol type="1">
<li>This is the reconstruction loss of the last denoising step and it can be ignored during training for the following reasons: It can be approximated using the same neural network in <span class="math inline">\(L_{t-1}\)</span>. Ignoring it makes the sample quality better and makes it simpler to implement.</li>
</ol></li>
</ol>
<h3 id="simplified-loss-todo">Simplified Loss (ToDo)</h3>
<p>So the final simplified training objective (<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2006.11239">Ho et al. (2020)</a> empirically found that training the diffusion model works better with a simplified objective that ignores the weighting term) is as follows:</p>
<p><img src="https://i.imgur.com/sMyAqVN.png" srcset="/img/loading.gif" lazyload width="400" /></p>
<h2 id="with-unet-model">With UNet model ***</h2>
<ul>
<li>A random time step t will be selected for each training sample (image).</li>
<li>Apply the Gaussian noise (corresponding to t) to each image.</li>
<li>Convert the time steps to embeddings (vectors).</li>
</ul>
<p><img src="https://i.imgur.com/PmD5Azy.png" srcset="/img/loading.gif" lazyload width="600" /></p>
<h2 id="training-1">Training</h2>
<p><img src="https://i.imgur.com/bnNS9z4.png" srcset="/img/loading.gif" lazyload width="400" /></p>
<h3 id="training-step">training step</h3>
<p>The official training algorithm is as above, and the following diagram is an illustration of how a training step works</p>
<p><img src="https://i.imgur.com/LgIOlQO.png" srcset="/img/loading.gif" lazyload width="600" /></p>
<h2 id="reverse-diffusion-sampling">Reverse Diffusion (Sampling)</h2>
<p><img src="https://i.imgur.com/F2EuVPU.png" srcset="/img/loading.gif" lazyload width="400" /></p>
<h3 id="generating-step">generating step</h3>
<p>We can generate images from noises using the above algorithm. The following diagram is an illustration of it. Note that in the last step, we simply output the learned mean <span class="math inline">\(\mu_\theta(x_{t=1}, t=1)\)</span> without adding the extra noise to it.</p>
<p><img src="https://i.imgur.com/wQIehey.png" srcset="/img/loading.gif" lazyload width="600" /></p>
<h2 id="summary">Summary</h2>
<p>Summary Here are some main takeaways from this article:</p>
<ul>
<li>The Diffusion model is divided into two parts: forward diffusion and reverse diffusion.</li>
<li>The forward diffusion can be done using the closed-form formula.</li>
<li>The backward diffusion can be done using a trained neural network.</li>
<li>To approximate the desired denoising step q, we just need to approximate the noise <span class="math inline">\(\epsilon_t\)</span> using a neural network <span class="math inline">\(\epsilon_\theta\)</span>.</li>
<li>Training on the simplified loss function yields better sample quality.</li>
</ul>
<h1 id="literature-review">Literature review</h1>
<ul>
<li>An example of training a diffusion model for modeling a 2D swiss roll data. (Image source: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1503.03585">Sohl-Dickstein et al., 2015</a>)
<ul>
<li><img src="https://i.imgur.com/oVtF9Tt.png" srcset="/img/loading.gif" lazyload width="500" /></li>
</ul></li>
</ul>
<h1 id="questions">Questions</h1>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/613852600/answer/3273556154">diffusion预测噪声为什么用UNET模型呢？ - 章彦博的回答 - 知乎</a>
<ul>
<li>其中的 <span class="math inline">\(\epsilon_\theta\)</span> 就直接是你要訓練的模型了，它是用來預測噪音 <span class="math inline">\(\epsilon\)</span> 的。但我們知道，<strong>噪音都是高頻的</strong>，不存在低維度的特徵，神經網路很難學習。同時， <span class="math inline">\(x_0\)</span> 通常是光滑的，神經網路會比較容易學到。</li>
<li>不使用UNet的話，這裡就直接用一個兩層全連接網路來預測雜訊。看起來是個很簡單的任務，但效果非常差。跑了100個epoch，想著就算沒有收斂，怎麼樣也能學個大概。結果沒想到，不光沒學個大概，連數值範圍都爆炸了</li>
<li>然後我把epoch設到了10000，數值範圍終於接近了，但效果還是很差。我猜想這就是噪音惹的禍。神經網路努力地去學習高頻的噪聲，從而忽略了低頻的範圍訊息</li>
<li><span class="math inline">\(\epsilon = \dfrac{x_t - \sqrt{1-\bar{\alpha}_t} x_{0}}{\sqrt{1-\bar{\alpha}_t}}\)</span></li>
<li><span class="math inline">\(\text{UNet}(x) = g(x + f(x))\)</span>, 它恰好和上式有類似的結構.</li>
<li>試驗的: <span class="math inline">\(\epsilon_\theta(x_t, t) = x_t + f(x_t, t)\)</span>, 改了之後，效果立刻就好起來了。而且就算不收斂，數值範圍也不會爆炸</li>
<li>如果認為神經網路能擬合一切的話，確實本質上是一樣的。但你加了U-Net / ResNet的結構之後，網路會更容易發現較好的解。而且我的實驗表明，如果沒有這樣的結構，網路在收斂之前的行為非常差。我猜是因為<strong>epsilon是高頻</strong>的，而神經網路很難從這樣的數據中學習。</li>
<li>至於一開始為什麼會使用UNet，因為 Noise 本身其實是一個很特殊的訊息，並不適用於傳統的神經網路來學習。 UNet因為獨特的 Skip connection 架構可以很好的學到 <strong>Noise裡的高頻訊息</strong>，如果嘗試用FC層的神經網路來預測Noise，效果會非常炸裂</li>
</ul></li>
</ul>
<h1 id="diffusion-models-vs-gans-vs-vaes">Diffusion Models vs GANs vs VAEs</h1>
<p>擴散模型（Diffusion Models）與傳統的生成對抗網絡（GANs）和變分自編碼器（VAEs）相比，具有多項顯著的優勢和特點。以下是這三種生成模型的比較：</p>
<h2 id="穩定性">1. <strong>穩定性</strong></h2>
<ul>
<li><strong>擴散模型</strong>：訓練過程相對穩定，不容易出現梯度消失或爆炸等問題。這使得擴散模型在訓練時更易於優化，並且能夠生成高質量的樣本。</li>
<li><strong>GANs</strong>：訓練過程不穩定，容易出現模式崩潰（mode collapse），即生成器只能生成有限類型的數據，這限制了其多樣性。</li>
<li><strong>VAEs</strong>：雖然訓練過程較為穩定，但生成的數據多樣性相對較低，可能不適合需要高多樣性的應用。</li>
</ul>
<h2 id="生成質量">2. <strong>生成質量</strong></h2>
<ul>
<li><strong>擴散模型</strong>：能夠捕捉到更多的細節信息，生成更加真實、細膩的圖像。這使得擴散模型在圖像生成等任務中表現出色。</li>
<li><strong>GANs</strong>：在生成質量方面通常表現良好，特別是在需要高保真度的應用中，如圖像合成和風格轉換。</li>
<li><strong>VAEs</strong>：雖然訓練穩定，但生成的數據質量可能不如GANs高，因此在複雜數據生成任務中表現較弱。</li>
</ul>
<h2 id="計算資源與效率">3. <strong>計算資源與效率</strong></h2>
<ul>
<li><strong>擴散模型</strong>：在訓練和生成過程中需要消耗大量計算資源，並且由於需要多次迭代和反向擴散過程，導致采樣速度較慢。</li>
<li><strong>GANs</strong>：通常需要較大的計算資源，但一旦訓練完成，其生成速度相對較快。</li>
<li><strong>VAEs</strong>：計算量相對較小，訓練過程較快，但可能無法產生足夠多樣化的數據。</li>
</ul>
<h2 id="可控性">4. <strong>可控性</strong></h2>
<ul>
<li><strong>擴散模型</strong>：具有良好的可控性，可以通過調整擴散步長、噪聲強度等參數來精細控制生成結果，以滿足用戶需求。</li>
<li><strong>GANs</strong>：可控性較差，因為生成器和判別器之間的對抗性質使得難以直接控制輸出特徵。</li>
<li><strong>VAEs</strong>：通過隱變量進行控制，但可控性通常不如擴散模型強。</li>
</ul>
<h2 id="應用場景">5. <strong>應用場景</strong></h2>
<ul>
<li><strong>擴散模型</strong>：已在計算機視覺、自然語言處理、語音合成等多個領域取得成功應用，如圖像生成、超分辨率、去噪等任務。</li>
<li><strong>GANs</strong>：廣泛應用於圖像生成、風格轉換等需要高質量生成的場景。</li>
<li><strong>VAEs</strong>：更適合於數據分析、降維等應用場景，並且具有良好的解釋性。</li>
</ul>
<h2 id="總結-1">總結</h2>
<p>總體而言，擴散模型在穩定性、生成質量和可控性方面展現了顯著優勢，使其成為當前深度學習領域中一個重要的研究方向。隨著技術的不斷發展，擴散模型有望在更多應用中取代傳統的GANs和VAEs。</p>
<h1 id="references">References</h1>
<ol type="1">
<li><a target="_blank" rel="noopener" href="https://roysubhradip.hashnode.dev/a-beginners-guide-to-diffusion-models-understanding-the-basics-and-beyond">A Beginner's Guide to Diffusion Models: Understanding the Basics and Beyond | Subhradip Roy's Blog (<strong>Recommend</strong>)</a></li>
<li><a target="_blank" rel="noopener" href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#forward-diffusion-process">What are Diffusion Models? (<strong>Recommend</strong>)</a></li>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLJV_el3uVTsNi7PgekEUFsyVllAJXRsP-">【生成式AI】淺談圖像生成模型 Diffusion Model 原理</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.cnbang.net/tech/3823/">理解 Stable Diffusion UNet 网络</a></li>
<li><a target="_blank" rel="noopener" href="https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/">Introduction to Diffusion Models for Machine Learning</a></li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/ML/" class="category-chain-item">ML</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/AI/" class="print-no-link">#AI</a>
      
        <a href="/tags/ML/" class="print-no-link">#ML</a>
      
        <a href="/tags/pytorch/" class="print-no-link">#pytorch</a>
      
        <a href="/tags/Diffusion/" class="print-no-link">#Diffusion</a>
      
        <a href="/tags/UNet/" class="print-no-link">#UNet</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>ML | Diffusion Models (Denoising diffusion probabilistic models)</div>
      <div>https://waipangsze.github.io/2024/12/15/ML-Diffusion-Models/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>wpsze</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>December 15, 2024</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Updated on</div>
          <div>February 3, 2025</div>
        </div>
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/12/18/CFD-RANS-URANS-LES/" title="CFD | RANS vs. URANS vs. LES">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">CFD | RANS vs. URANS vs. LES</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/12/13/ML-Unet/" title="ML | U-Net">
                        <span class="hidden-mobile">ML | U-Net</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.utils.listenDOMLoaded(function() {
      Fluid.events.registerRefreshCallback(function() {
        if ('mermaid' in window) {
          mermaid.init();
        }
      });
    });
  });
</script>






<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9HL36SZ28R"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9HL36SZ28R');
</script>

    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">

  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  

  <span id="sitetime"></span>
  <script language=javascript>
    function siteTime(){
      window.setTimeout("siteTime()", 1000);
      var seconds = 1000;
      var minutes = seconds * 60;
      var hours = minutes * 60;
      var days = hours * 24;
      var years = days * 365;
      var today = new Date();
      var todayYear = today.getFullYear();
      var todayMonth = today.getMonth()+1;
      var todayDate = today.getDate();
      var todayHour = today.getHours();
      var todayMinute = today.getMinutes();
      var todaySecond = today.getSeconds();
      /* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
      year - 作为date对象的年份，为4位年份值
      month - 0-11之间的整数，做为date对象的月份
      day - 1-31之间的整数，做为date对象的天数
      hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
      minutes - 0-59之间的整数，做为date对象的分钟数
      seconds - 0-59之间的整数，做为date对象的秒数
      microseconds - 0-999之间的整数，做为date对象的毫秒数 */
      var t1 = Date.UTC(2023,04,23,00,00,00); //北京时间2018-2-13 00:00:00
      var t2 = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
      var diff = t2-t1;
      var diffYears = Math.floor(diff/years);
      var diffDays = Math.floor((diff/days)-diffYears*365);
      var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
      var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
      var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
      /*document.getElementById("sitetime").innerHTML=" 已运行"+/*diffYears+" 年 "+*/diffDays+" 天 "+diffHours+" 小时 "+diffMinutes+" 分钟 "+diffSeconds+" 秒";
      document.getElementById("sitetime").innerHTML=" 已運行"+diffYears+" 年 "+diffDays+" 天 ";
    }/*因为建站时间还没有一年，就将之注释掉了。需要的可以取消*/
    siteTime();
  </script>
  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
