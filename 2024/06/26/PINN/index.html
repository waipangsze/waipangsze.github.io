

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=light>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="wpsze">
  <meta name="keywords" content="">
  
    <meta name="description" content="PINN Physics-informed neural networks (PINNs) represent a significant advancement in the integration of machine learning with physical laws, particularly in the context of solving differential equatio">
<meta property="og:type" content="article">
<meta property="og:title" content="Physics-informed neural networks (PINN)">
<meta property="og:url" content="https://waipangsze.github.io/2024/06/26/PINN/index.html">
<meta property="og:site_name" content="wpsze">
<meta property="og:description" content="PINN Physics-informed neural networks (PINNs) represent a significant advancement in the integration of machine learning with physical laws, particularly in the context of solving differential equatio">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/9/90/Physics-informed_nerural_networks.png">
<meta property="og:image" content="https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11071-023-08654-w/MediaObjects/11071_2023_8654_Fig19_HTML.png">
<meta property="article:published_time" content="2024-06-26T06:00:00.000Z">
<meta property="article:modified_time" content="2024-10-23T05:44:32.381Z">
<meta property="article:author" content="wpsze">
<meta property="article:tag" content="PINN">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://upload.wikimedia.org/wikipedia/commons/9/90/Physics-informed_nerural_networks.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>Physics-informed neural networks (PINN) - wpsze</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"waipangsze.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>wpsze</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>Links</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/bookmark/" target="_self">
                <i class="iconfont icon-bookmark"></i>
                <span>Bookmarks</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About Me</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                <span>Docs</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/Meteorology/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>Meteorology</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/monitor/" target="_self">
                    
                    <span>Real Time Monitor</span>
                  </a>
                
              </div>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Physics-informed neural networks (PINN)"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-06-26 14:00" pubdate>
          June 26, 2024 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          425 words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          4 mins
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> views
        </span>
        

      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Physics-informed neural networks (PINN)</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="pinn">PINN</h1>
<p>Physics-informed neural networks (PINNs) represent a significant advancement in the integration of machine learning with physical laws, particularly in the context of solving differential equations. They combine traditional neural network approaches with the constraints provided by known physics, enabling more accurate modeling and predictions in various scientific fields.</p>
<figure>
<img src="https://upload.wikimedia.org/wikipedia/commons/9/90/Physics-informed_nerural_networks.png" srcset="/img/loading.gif" lazyload alt="PINN" width="500" /><figcaption>PINN</figcaption>
</figure>
<h1 id="universal-approximation-theorem">Universal Approximation Theorem</h1>
<p><strong>Definition</strong></p>
<p>The theorem states that for <strong>any continuous function</strong> $ f: ^n  $ defined on a compact subset of $ ^n $, there exists a neural network $ g $ such that the difference between $ f $ and $ g $ can be made arbitrarily small. Formally, for any $ &gt; 0 $, there exists a neural network with a finite number of neurons such that:</p>
<p><span class="math display">\[
| f(x) - g(x) | &lt; \epsilon
\]</span></p>
<p>for all $ x $ in the domain of interest.</p>
<p><strong>Historical Background</strong></p>
<p>The theorem was independently proven by George Cybenko in 1989, who focused on networks using sigmoid activation functions, and later by Kurt Hornik in 1991, who generalized it to include other activation functions like ReLU (Rectified Linear Unit).</p>
<p><strong>Implications</strong></p>
<p>It has profound implications for the design and understanding of neural networks:</p>
<ul>
<li><strong>Expressive Power</strong>: It guarantees that neural networks can model complex relationships in data, making them suitable for tasks like image classification, function approximation, and more.</li>
<li><strong>Architecture Design</strong>: The theorem informs users about the necessary architecture (e.g., number of layers and neurons) required to achieve desired approximations.</li>
</ul>
<p><strong>Limitations</strong></p>
<p>While the UAT provides a theoretical foundation, it does not address practical aspects such as:</p>
<ul>
<li><strong>Generalization</strong>: The ability of a network to perform well on unseen data is not guaranteed by the theorem alone. Techniques like regularization and cross-validation are necessary to improve generalization.</li>
<li><strong>Computational Feasibility</strong>: The theorem does not specify how to construct the network or find the optimal parameters effectively. In practice, training methods like backpropagation are used, but they may not always reach the global optimum.</li>
</ul>
<p><strong>Reading</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.deep-mind.org/2023/03/26/the-universal-approximation-theorem/">The Universal Approximation Theorem</a></li>
<li><a target="_blank" rel="noopener" href="https://mitliagkas.github.io/ift6085-2020/ift-6085-lecture-10-notes.pdf">Expressivity and Universal Approximation Theorems Part 1</a></li>
</ul>
<h2 id="for-function-alone">For function alone,</h2>
<ul>
<li>Chen, T., &amp; Chen, H. (1993). Approximations of continuous functionals by neural networks with application to dynamic systems. IEEE Transactions on Neural networks, 4(6), 910-918.</li>
</ul>
<p>Theorem 2: Suppose that <span class="math inline">\(U\)</span> is a compact set in <span class="math inline">\(C[a,b]\)</span>, <span class="math inline">\(f\)</span> is a continuous functional defined on <span class="math inline">\(U\)</span>, and <span class="math inline">\(\sigma (x)\)</span> is a bounded generalized sigmoidal function, then for any <span class="math inline">\(\epsilon &gt; 0\)</span>, there exist <span class="math inline">\(m+1\)</span> points $ a = x_0 &lt;...&lt; x_m = b$, a positive integer <span class="math inline">\(N\)</span> and constants <span class="math inline">\(c_{ij}, \theta_{ij}, \xi_{ij}\)</span>, <span class="math inline">\(i=1,...,N\)</span>, <span class="math inline">\(j=0,1,...,m\)</span>, such that</p>
<p><span class="math display">\[
| f(u) - \sum_{i=1}^N c_i g ( \sum_{j=0}^m \xi_{ij} u(x_{j}) + \theta_i) | &lt; \epsilon, \qquad \forall u \in U 
\]</span></p>
<p>or</p>
<p><span class="math display">\[
| f(u) - \sum_{i=1}^N c_i g (\mathbf{\omega_j} \cdot \mathbf{x} + \theta_i) | &lt; \epsilon, \qquad \forall u \in U
\]</span></p>
<h2 id="for-operator">For operator,</h2>
<ul>
<li>Chen, T., &amp; Chen, H. (1995). Universal approximation to nonlinear operators by neural networks with arbitrary activation functions and its application to dynamical systems. IEEE transactions on neural networks, 6(4), 911-917.</li>
</ul>
<p>Theorem 5: Suppose that <span class="math inline">\(g\in (TW)\)</span>, <span class="math inline">\(X\)</span> is a Banach Space, <span class="math inline">\(K_1 X, K_2 R^n\)</span> are two compact sets in <span class="math inline">\(X\)</span> and <span class="math inline">\(R^n\)</span> respectively, <span class="math inline">\(V\)</span> is a compace set in <span class="math inline">\(C(K_1)\)</span>, <span class="math inline">\(G\)</span> is a nonlinear continuous operator, which maps <span class="math inline">\(V\)</span> into <span class="math inline">\(C(K_2)\)</span>, then for any $&gt;0 $, there are positive integers <span class="math inline">\(M, N, m\)</span> constants <span class="math inline">\(c_i^k, \zeta_k, \xi_{ij}^k \in R^n\)</span>, <span class="math inline">\(x_j \in K_1, i=1,...,M, k=1,...,N, j=1,...,m\)</span>, such that</p>
<p><span class="math display">\[
| G(u)(y) - \sum_{k=1}^N \sum_{i=1}^M c_i^k g( \sum_{j=1}^m \xi_{ij} u(x_{j}) + \theta_i^k) g(\omega_k \cdot y + \xi_k)| &lt; \epsilon, \qquad \forall u \in U 
\]</span></p>
<h1 id="definition-and-functionality">Definition and Functionality</h1>
<p>PINNs are a type of <strong>universal function approximator</strong> that incorporates physical laws directly into the training process of neural networks. This is achieved by embedding governing equations, typically expressed as partial differential equations (PDEs), into the loss function of the network. By doing so, PINNs ensure that the solutions generated are consistent with these physical laws, which enhances the robustness and accuracy of the model even when data availability is limited</p>
<p><strong>Training Mechanism</strong></p>
<p>The training of a PINN involves two main components:</p>
<ol type="1">
<li><strong>Data Loss</strong>: The standard supervised learning approach minimizes the mean squared error (MSE) between <strong>predicted outputs and actual data</strong>.</li>
<li><strong>Physics Loss</strong>: An additional term is introduced to the loss function that quantifies <strong>how well the predicted outputs satisfy the governing physical equations</strong>. This is done by computing gradients (<strong>using automatic differentiation</strong>) at sampled points in space and time, allowing for the evaluation of residuals from the PDEs.</li>
</ol>
<p>This dual approach allows PINNs to <strong>leverage both empirical data and theoretical knowledge</strong>, making them particularly effective for problems where data is scarce or noisy.</p>
<h2 id="challenges-and-future-directions">Challenges and Future Directions</h2>
<p>Despite their advantages, PINNs also face challenges:</p>
<ul>
<li><strong>Computational Cost</strong>: Training PINNs can be computationally intensive, especially when dealing with <strong>complex geometries</strong> or <strong>high-dimensional problems</strong>.</li>
<li><strong>Generalization Limitations</strong>: Regular PINNs typically require <strong>retraining for different geometries or boundary conditions</strong>, which can limit their efficiency in practical applications.</li>
</ul>
<h1 id="pinn-1">PINN</h1>
<h2 id="key-points-on-using-collocation-points-in-pinns">Key Points on Using Collocation Points in PINNs</h2>
<figure>
<img src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11071-023-08654-w/MediaObjects/11071_2023_8654_Fig19_HTML.png" srcset="/img/loading.gif" lazyload alt="Collocation Points" /><figcaption>Collocation Points</figcaption>
</figure>
<p>It is possible to use collocation points only in Physics-Informed Neural Networks (PINNs). Collocation points are specific locations in the domain where the residuals of the governing equations are evaluated, and they play a crucial role in training PINNs.</p>
<p><strong>1. Definition and Role</strong></p>
<p>Collocation points serve as the training dataset for PINNs, where the network learns to <strong>minimize the residuals of the partial differential equations (PDEs) at these discrete points</strong>. The objective is to ensure that the neural network's output satisfies the physical laws represented by these equations at the selected collocation points.</p>
<p><strong>2. Training with Collocation Points</strong></p>
<p>The training process involves minimizing a loss function that combines:</p>
<ul>
<li><strong>Data Loss</strong>: Measures how well the model fits any <strong>available observational data</strong>.</li>
<li><strong>Physics Loss</strong>: Enforces that the residuals of the PDEs at the <strong>collocation points</strong> are minimized.</li>
</ul>
<p>Using only collocation points can be effective, especially when there is limited observational data. However, it is essential to select these points wisely, as their distribution can significantly affect the accuracy and convergence of the solution. <strong>Strategies such as adaptive selection of collocation points</strong> based on residual analysis or problem-specific features can enhance performance.</p>
<p><strong>3. Limitations and Considerations</strong></p>
<p>While using collocation points alone is feasible, there are considerations:</p>
<ul>
<li><strong>Distribution of Points</strong>: A uniform distribution may not capture complex behaviors in certain regions of the domain effectively. <strong>Adaptive methods that focus on areas with higher residuals or complexity</strong> can improve training efficiency and solution accuracy.</li>
<li><strong>Generalization</strong>: Relying solely on collocation points may limit the model's ability to generalize across different scenarios or boundary conditions unless carefully managed.</li>
</ul>
<p>In summary, using only collocation points in PINNs is a valid approach, but careful consideration of their selection and distribution is crucial for achieving accurate and reliable results.</p>
<h2 id="strategies-for-selecting-collocation-points">Strategies for Selecting Collocation Points</h2>
<p><strong>1. Uniform Sampling</strong></p>
<ul>
<li><strong>Description</strong>: Initially, many PINNs utilize a uniform sampling strategy, distributing collocation points evenly across the domain.</li>
<li><strong>Limitations</strong>: This method may lead to inefficiencies, especially in complex problems where certain regions require more focus due to higher gradients or residuals.</li>
</ul>
<p><strong>2. Adaptive Sampling Techniques</strong></p>
<ul>
<li><strong>Dynamic Adjustment</strong>: Adaptive strategies adjust the locations of collocation points during training based on the residuals of the PDEs. This allows the network to concentrate on areas where the solution is more complex or where errors are larger.</li>
<li><strong>Examples</strong>:
<ul>
<li><strong>PINNACLE Method</strong>: This method dynamically selects collocation and experimental points by analyzing training dynamics and adjusting point locations based on performance metrics. It improves accuracy and convergence speed by focusing on regions with significant residuals.</li>
<li><strong>Residual-Based Sampling</strong>: Points are selected based on the distribution of residuals, with higher densities in areas exhibiting larger errors. This method can involve <strong>resampling after a set number of iterations to avoid local minima</strong>.</li>
</ul></li>
</ul>
<p><strong>3. Weighting Collocation Points</strong></p>
<ul>
<li><strong>Variable Influence</strong>: Assign different weights to collocation points based on their importance, allowing the model to focus more on points with higher loss values. This approach helps prioritize learning in critical areas of the solution space.</li>
</ul>
<p><strong>4. Probability Density Functions (PDFs)</strong></p>
<ul>
<li><strong>Guided Distribution</strong>: Use information from residuals to create a probability density function that guides the distribution of collocation points. This can lead to a non-uniform distribution that better captures the essential features of the solution.</li>
</ul>
<p><strong>5. Hybrid Approaches</strong></p>
<ul>
<li>Combining fixed and adaptive methods can also be beneficial. For instance, starting with uniformly distributed points and then adapting their locations based on observed performance can provide a balanced approach.</li>
</ul>
<p>In conclusion, <strong>selecting collocation points in PINNs is an iterative process</strong> that can significantly impact the model's efficiency and accuracy. Adaptive methods that focus on error distribution and dynamic adjustments during training are particularly effective, as demonstrated by recent advancements like the PINNACLE method. These strategies allow for better representation of complex physical phenomena while optimizing computational resources.</p>
<h1 id="video">Video</h1>
<ul>
<li>Steve Brunton</li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/-zrY7P2dVC4?si=u64XUih1hSEUEv6o" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
</iframe>
<h1 id="references">References</h1>
<ol type="1">
<li>Raissi, M., Perdikaris, P., &amp; Karniadakis, G. E. (2019). Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. Journal of Computational physics, 378, 686-707.</li>
<li>Karniadakis, G. E., Kevrekidis, I. G., Lu, L., Perdikaris, P., Wang, S., &amp; Yang, L. (2021). Physics-informed machine learning. Nature Reviews Physics, 3(6), 422-440.</li>
<li>Lu, L., Jin, P., Pang, G., Zhang, Z., &amp; Karniadakis, G. E. (2021). Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators. Nature machine intelligence, 3(3), 218-229.</li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/ML/" class="category-chain-item">ML</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/PINN/" class="print-no-link">#PINN</a>
      
        <a href="/tags/AI/" class="print-no-link">#AI</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Physics-informed neural networks (PINN)</div>
      <div>https://waipangsze.github.io/2024/06/26/PINN/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>wpsze</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>June 26, 2024</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Updated on</div>
          <div>October 23, 2024</div>
        </div>
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/07/04/ssh_tunnel/" title="ssh tunnel">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">ssh tunnel</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/06/25/PINN-JAX/" title="JAX">
                        <span class="hidden-mobile">JAX</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.utils.listenDOMLoaded(function() {
      Fluid.events.registerRefreshCallback(function() {
        if ('mermaid' in window) {
          mermaid.init();
        }
      });
    });
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">

  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  

  <span id="sitetime"></span>
  <script language=javascript>
    function siteTime(){
      window.setTimeout("siteTime()", 1000);
      var seconds = 1000;
      var minutes = seconds * 60;
      var hours = minutes * 60;
      var days = hours * 24;
      var years = days * 365;
      var today = new Date();
      var todayYear = today.getFullYear();
      var todayMonth = today.getMonth()+1;
      var todayDate = today.getDate();
      var todayHour = today.getHours();
      var todayMinute = today.getMinutes();
      var todaySecond = today.getSeconds();
      /* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
      year - 作为date对象的年份，为4位年份值
      month - 0-11之间的整数，做为date对象的月份
      day - 1-31之间的整数，做为date对象的天数
      hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
      minutes - 0-59之间的整数，做为date对象的分钟数
      seconds - 0-59之间的整数，做为date对象的秒数
      microseconds - 0-999之间的整数，做为date对象的毫秒数 */
      var t1 = Date.UTC(2023,04,23,00,00,00); //北京时间2018-2-13 00:00:00
      var t2 = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
      var diff = t2-t1;
      var diffYears = Math.floor(diff/years);
      var diffDays = Math.floor((diff/days)-diffYears*365);
      var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
      var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
      var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
      /*document.getElementById("sitetime").innerHTML=" 已运行"+/*diffYears+" 年 "+*/diffDays+" 天 "+diffHours+" 小时 "+diffMinutes+" 分钟 "+diffSeconds+" 秒";
      document.getElementById("sitetime").innerHTML=" 已運行"+diffYears+" 年 "+diffDays+" 天 ";
    }/*因为建站时间还没有一年，就将之注释掉了。需要的可以取消*/
    siteTime();
  </script>
  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
